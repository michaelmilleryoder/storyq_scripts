{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Investigate logistic regression intercept with text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try normalization on Yelp review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Amazing food. Glorious bevs. What more could y...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Wife and I have been going to Abuelos for year...</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I had THE BEST VEGAN Gardein chicken plate wit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Went there for the first time today and got ve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>After my second time here I'm still leaving fu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text    rating  is_positive\n",
       "0     As someone who has worked with many museums, I...  negative        False\n",
       "1     I am actually horrified this place is still in...  negative        False\n",
       "2     I love Deagan's. I do. I really do. The atmosp...  positive         True\n",
       "3     Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  negative        False\n",
       "4     Oh happy day, finally have a Canes near my cas...  positive         True\n",
       "...                                                 ...       ...          ...\n",
       "9995  Amazing food. Glorious bevs. What more could y...  positive         True\n",
       "9996  Wife and I have been going to Abuelos for year...  negative        False\n",
       "9997  I had THE BEST VEGAN Gardein chicken plate wit...  positive         True\n",
       "9998  Went there for the first time today and got ve...  positive         True\n",
       "9999  After my second time here I'm still leaving fu...  positive         True\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load review data\n",
    "import pandas as pd\n",
    "path = '/data/storyq/yelp_dataset/review_sample.csv'\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "data['is_positive'] = data.rating.map(lambda x: True if x=='positive' else False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 113)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = data['review_text']\n",
    "vectorizer = CountVectorizer(min_df=1000)\n",
    "feats = vectorizer.fit_transform(corpus) # corpus is a list of strings (documents)\n",
    "print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38697222, -0.34774403, -0.32728854, ...,  2.59369408,\n",
       "         2.0023615 , -0.35231082],\n",
       "       [ 1.27171711,  1.68942076, -0.32728854, ..., -0.42996421,\n",
       "         0.09819169, -0.35231082],\n",
       "       [-0.38697222, -0.34774403, -0.32728854, ..., -0.42996421,\n",
       "         1.36763823, -0.35231082],\n",
       "       ...,\n",
       "       [-0.38697222, -0.34774403, -0.32728854, ..., -0.42996421,\n",
       "         0.09819169, -0.35231082],\n",
       "       [ 1.27171711, -0.34774403, -0.32728854, ...,  1.08186493,\n",
       "         0.09819169,  4.61214413],\n",
       "       [-0.38697222,  1.68942076, -0.32728854, ..., -0.42996421,\n",
       "         0.09819169,  1.3025075 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "# scaler = StandardScaler(with_mean=False)\n",
    "scaler = StandardScaler()\n",
    "# feats_norm = scaler.fit_transform(sm.add_constant(feats.A))\n",
    "feats_norm = scaler.fit_transform(feats.A)\n",
    "feats_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02920484, -0.02624428, -0.0247005 , ...,  0.19574638,\n",
       "         0.15111844, -0.02658894],\n",
       "       [ 0.09131528,  0.12130837, -0.02350086, ..., -0.03087345,\n",
       "         0.00705063, -0.02529758],\n",
       "       [-0.04045508, -0.03635406, -0.03421559, ..., -0.04494957,\n",
       "         0.14297644, -0.03683148],\n",
       "       ...,\n",
       "       [-0.06845064, -0.06151166, -0.05789333, ..., -0.0760554 ,\n",
       "         0.01736891, -0.06231947],\n",
       "       [ 0.1168897 , -0.03196284, -0.03008268, ...,  0.09943946,\n",
       "         0.00902528,  0.42392457],\n",
       "       [-0.04767385,  0.20813173, -0.040321  , ..., -0.05297034,\n",
       "         0.01209693,  0.16046514]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "# feats_n = normalize(sm.add_constant(feats.A))\n",
    "feats_n = normalize(feats_norm)\n",
    "feats_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286534\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  9886</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>   113</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 17 Feb 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.4936</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:57:47</td>     <th>  Log-Likelihood:    </th> <td> -2865.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -5658.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.1348</td> <td>    0.057</td> <td>   37.505</td> <td> 0.000</td> <td>    2.023</td> <td>    2.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.6741</td> <td>    0.406</td> <td>   -1.660</td> <td> 0.097</td> <td>   -1.470</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -2.0009</td> <td>    0.372</td> <td>   -5.377</td> <td> 0.000</td> <td>   -2.730</td> <td>   -1.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.8580</td> <td>    0.348</td> <td>   -2.467</td> <td> 0.014</td> <td>   -1.540</td> <td>   -0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.1498</td> <td>    0.397</td> <td>    2.896</td> <td> 0.004</td> <td>    0.372</td> <td>    1.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.2325</td> <td>    0.416</td> <td>    2.963</td> <td> 0.003</td> <td>    0.417</td> <td>    2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    2.9196</td> <td>    0.461</td> <td>    6.337</td> <td> 0.000</td> <td>    2.017</td> <td>    3.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    8.2041</td> <td>    0.712</td> <td>   11.528</td> <td> 0.000</td> <td>    6.809</td> <td>    9.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0769</td> <td>    0.384</td> <td>    0.200</td> <td> 0.841</td> <td>   -0.675</td> <td>    0.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    4.9761</td> <td>    0.682</td> <td>    7.292</td> <td> 0.000</td> <td>    3.639</td> <td>    6.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.2289</td> <td>    0.419</td> <td>    0.547</td> <td> 0.585</td> <td>   -0.592</td> <td>    1.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    1.2145</td> <td>    0.433</td> <td>    2.803</td> <td> 0.005</td> <td>    0.365</td> <td>    2.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -1.6340</td> <td>    0.415</td> <td>   -3.937</td> <td> 0.000</td> <td>   -2.447</td> <td>   -0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.8741</td> <td>    0.361</td> <td>   -2.421</td> <td> 0.015</td> <td>   -1.582</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -1.8264</td> <td>    0.410</td> <td>   -4.453</td> <td> 0.000</td> <td>   -2.630</td> <td>   -1.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -1.4679</td> <td>    0.378</td> <td>   -3.883</td> <td> 0.000</td> <td>   -2.209</td> <td>   -0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.8294</td> <td>    0.403</td> <td>   -2.056</td> <td> 0.040</td> <td>   -1.620</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    4.9991</td> <td>    0.454</td> <td>   11.018</td> <td> 0.000</td> <td>    4.110</td> <td>    5.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.6834</td> <td>    0.435</td> <td>   -1.571</td> <td> 0.116</td> <td>   -1.536</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.2757</td> <td>    0.380</td> <td>   -0.726</td> <td> 0.468</td> <td>   -1.021</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.4593</td> <td>    0.393</td> <td>   -1.170</td> <td> 0.242</td> <td>   -1.229</td> <td>    0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.8176</td> <td>    0.411</td> <td>    1.990</td> <td> 0.047</td> <td>    0.012</td> <td>    1.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.1994</td> <td>    0.370</td> <td>    0.539</td> <td> 0.590</td> <td>   -0.526</td> <td>    0.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.5498</td> <td>    0.380</td> <td>   -1.448</td> <td> 0.147</td> <td>   -1.294</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    3.8696</td> <td>    0.450</td> <td>    8.597</td> <td> 0.000</td> <td>    2.987</td> <td>    4.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    7.1805</td> <td>    0.697</td> <td>   10.302</td> <td> 0.000</td> <td>    5.814</td> <td>    8.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.8337</td> <td>    0.420</td> <td>    1.985</td> <td> 0.047</td> <td>    0.011</td> <td>    1.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -2.0762</td> <td>    0.379</td> <td>   -5.482</td> <td> 0.000</td> <td>   -2.819</td> <td>   -1.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.9839</td> <td>    0.384</td> <td>   -2.563</td> <td> 0.010</td> <td>   -1.736</td> <td>   -0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -2.1915</td> <td>    0.340</td> <td>   -6.439</td> <td> 0.000</td> <td>   -2.859</td> <td>   -1.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -1.0797</td> <td>    0.361</td> <td>   -2.990</td> <td> 0.003</td> <td>   -1.787</td> <td>   -0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.4986</td> <td>    0.361</td> <td>   -1.380</td> <td> 0.167</td> <td>   -1.207</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.2171</td> <td>    0.392</td> <td>    0.554</td> <td> 0.579</td> <td>   -0.550</td> <td>    0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -2.1160</td> <td>    0.347</td> <td>   -6.100</td> <td> 0.000</td> <td>   -2.796</td> <td>   -1.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.1314</td> <td>    0.441</td> <td>    0.298</td> <td> 0.766</td> <td>   -0.734</td> <td>    0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    3.4935</td> <td>    0.426</td> <td>    8.203</td> <td> 0.000</td> <td>    2.659</td> <td>    4.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.1457</td> <td>    0.380</td> <td>    0.383</td> <td> 0.702</td> <td>   -0.599</td> <td>    0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -1.3652</td> <td>    0.398</td> <td>   -3.432</td> <td> 0.001</td> <td>   -2.145</td> <td>   -0.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.3285</td> <td>    0.359</td> <td>   -0.915</td> <td> 0.360</td> <td>   -1.032</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    3.0541</td> <td>    0.375</td> <td>    8.136</td> <td> 0.000</td> <td>    2.318</td> <td>    3.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.6161</td> <td>    0.380</td> <td>   -1.620</td> <td> 0.105</td> <td>   -1.361</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    9.3381</td> <td>    0.503</td> <td>   18.571</td> <td> 0.000</td> <td>    8.353</td> <td>   10.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1342</td> <td>    0.442</td> <td>   -0.304</td> <td> 0.761</td> <td>   -1.000</td> <td>    0.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.3781</td> <td>    0.361</td> <td>   -1.047</td> <td> 0.295</td> <td>   -1.086</td> <td>    0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.2868</td> <td>    0.437</td> <td>   -0.657</td> <td> 0.511</td> <td>   -1.143</td> <td>    0.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.5777</td> <td>    0.501</td> <td>   -1.153</td> <td> 0.249</td> <td>   -1.560</td> <td>    0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.0794</td> <td>    0.352</td> <td>    0.226</td> <td> 0.822</td> <td>   -0.610</td> <td>    0.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.6242</td> <td>    0.428</td> <td>   -1.458</td> <td> 0.145</td> <td>   -1.463</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    1.7625</td> <td>    0.473</td> <td>    3.724</td> <td> 0.000</td> <td>    0.835</td> <td>    2.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    1.6032</td> <td>    0.475</td> <td>    3.377</td> <td> 0.001</td> <td>    0.673</td> <td>    2.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.6888</td> <td>    0.523</td> <td>   -1.318</td> <td> 0.187</td> <td>   -1.713</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -1.5593</td> <td>    0.373</td> <td>   -4.180</td> <td> 0.000</td> <td>   -2.291</td> <td>   -0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -1.3940</td> <td>    0.357</td> <td>   -3.906</td> <td> 0.000</td> <td>   -2.094</td> <td>   -0.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>    2.7611</td> <td>    0.436</td> <td>    6.328</td> <td> 0.000</td> <td>    1.906</td> <td>    3.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>    5.7134</td> <td>    0.572</td> <td>    9.984</td> <td> 0.000</td> <td>    4.592</td> <td>    6.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>    1.0591</td> <td>    0.379</td> <td>    2.797</td> <td> 0.005</td> <td>    0.317</td> <td>    1.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>   -0.6089</td> <td>    0.471</td> <td>   -1.293</td> <td> 0.196</td> <td>   -1.532</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>    0.0161</td> <td>    0.391</td> <td>    0.041</td> <td> 0.967</td> <td>   -0.749</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>   -0.2279</td> <td>    0.384</td> <td>   -0.593</td> <td> 0.553</td> <td>   -0.981</td> <td>    0.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>    1.8105</td> <td>    0.490</td> <td>    3.693</td> <td> 0.000</td> <td>    0.850</td> <td>    2.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>   -3.8810</td> <td>    0.353</td> <td>  -11.005</td> <td> 0.000</td> <td>   -4.572</td> <td>   -3.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>    2.1438</td> <td>    0.393</td> <td>    5.459</td> <td> 0.000</td> <td>    1.374</td> <td>    2.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>   -4.7827</td> <td>    0.375</td> <td>  -12.743</td> <td> 0.000</td> <td>   -5.518</td> <td>   -4.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>   -7.9012</td> <td>    0.445</td> <td>  -17.747</td> <td> 0.000</td> <td>   -8.774</td> <td>   -7.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>    1.6443</td> <td>    0.561</td> <td>    2.933</td> <td> 0.003</td> <td>    0.546</td> <td>    2.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>    1.0639</td> <td>    0.428</td> <td>    2.488</td> <td> 0.013</td> <td>    0.226</td> <td>    1.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>   -1.5643</td> <td>    0.398</td> <td>   -3.929</td> <td> 0.000</td> <td>   -2.345</td> <td>   -0.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>   -0.4831</td> <td>    0.342</td> <td>   -1.414</td> <td> 0.157</td> <td>   -1.153</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>   <td>   -0.8788</td> <td>    0.405</td> <td>   -2.167</td> <td> 0.030</td> <td>   -1.673</td> <td>   -0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>   <td>   -2.0247</td> <td>    0.379</td> <td>   -5.345</td> <td> 0.000</td> <td>   -2.767</td> <td>   -1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>   <td>   -1.8683</td> <td>    0.359</td> <td>   -5.211</td> <td> 0.000</td> <td>   -2.571</td> <td>   -1.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>   <td>   -0.5862</td> <td>    0.369</td> <td>   -1.589</td> <td> 0.112</td> <td>   -1.309</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>   <td>   -0.0082</td> <td>    0.520</td> <td>   -0.016</td> <td> 0.987</td> <td>   -1.027</td> <td>    1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>   <td>    0.0284</td> <td>    0.395</td> <td>    0.072</td> <td> 0.943</td> <td>   -0.745</td> <td>    0.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>   <td>   -2.7641</td> <td>    0.334</td> <td>   -8.268</td> <td> 0.000</td> <td>   -3.419</td> <td>   -2.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>   <td>   -1.2452</td> <td>    0.363</td> <td>   -3.432</td> <td> 0.001</td> <td>   -1.956</td> <td>   -0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>   <td>    0.1721</td> <td>    0.383</td> <td>    0.450</td> <td> 0.653</td> <td>   -0.578</td> <td>    0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>   <td>    0.2530</td> <td>    0.365</td> <td>    0.694</td> <td> 0.488</td> <td>   -0.462</td> <td>    0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>   <td>    2.3712</td> <td>    0.403</td> <td>    5.889</td> <td> 0.000</td> <td>    1.582</td> <td>    3.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>   <td>    0.0465</td> <td>    0.405</td> <td>    0.115</td> <td> 0.909</td> <td>   -0.748</td> <td>    0.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>   <td>   -1.9348</td> <td>    0.316</td> <td>   -6.129</td> <td> 0.000</td> <td>   -2.554</td> <td>   -1.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>   <td>   -1.4642</td> <td>    0.484</td> <td>   -3.028</td> <td> 0.002</td> <td>   -2.412</td> <td>   -0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>   <td>    1.1032</td> <td>    0.436</td> <td>    2.528</td> <td> 0.011</td> <td>    0.248</td> <td>    1.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>   <td>    0.5998</td> <td>    0.406</td> <td>    1.477</td> <td> 0.140</td> <td>   -0.196</td> <td>    1.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>   <td>    0.7346</td> <td>    0.382</td> <td>    1.923</td> <td> 0.054</td> <td>   -0.014</td> <td>    1.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>   <td>    0.6221</td> <td>    0.390</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.142</td> <td>    1.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>   <td>   -0.8785</td> <td>    0.540</td> <td>   -1.628</td> <td> 0.103</td> <td>   -1.936</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>   <td>   -2.6816</td> <td>    0.752</td> <td>   -3.564</td> <td> 0.000</td> <td>   -4.156</td> <td>   -1.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>   <td>   -0.0840</td> <td>    0.407</td> <td>   -0.206</td> <td> 0.836</td> <td>   -0.881</td> <td>    0.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>   <td>   -0.9477</td> <td>    0.393</td> <td>   -2.411</td> <td> 0.016</td> <td>   -1.718</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>   <td>   -1.1957</td> <td>    0.399</td> <td>   -2.996</td> <td> 0.003</td> <td>   -1.978</td> <td>   -0.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>   <td>   -1.2974</td> <td>    0.440</td> <td>   -2.952</td> <td> 0.003</td> <td>   -2.159</td> <td>   -0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>   <td>   -2.8771</td> <td>    0.463</td> <td>   -6.217</td> <td> 0.000</td> <td>   -3.784</td> <td>   -1.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>   <td>    0.3003</td> <td>    0.387</td> <td>    0.776</td> <td> 0.438</td> <td>   -0.459</td> <td>    1.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>   <td>   -2.1412</td> <td>    0.680</td> <td>   -3.148</td> <td> 0.002</td> <td>   -3.474</td> <td>   -0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>   <td>    0.1729</td> <td>    0.377</td> <td>    0.458</td> <td> 0.647</td> <td>   -0.567</td> <td>    0.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>   <td>    1.6550</td> <td>    0.403</td> <td>    4.109</td> <td> 0.000</td> <td>    0.866</td> <td>    2.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>   <td>   -1.4514</td> <td>    0.384</td> <td>   -3.778</td> <td> 0.000</td> <td>   -2.204</td> <td>   -0.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>   <td>   -0.4775</td> <td>    0.469</td> <td>   -1.018</td> <td> 0.308</td> <td>   -1.396</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>   <td>    0.8007</td> <td>    0.410</td> <td>    1.955</td> <td> 0.051</td> <td>   -0.002</td> <td>    1.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th>  <td>    1.5401</td> <td>    0.371</td> <td>    4.149</td> <td> 0.000</td> <td>    0.813</td> <td>    2.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th>  <td>   -1.8043</td> <td>    0.558</td> <td>   -3.234</td> <td> 0.001</td> <td>   -2.898</td> <td>   -0.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th>  <td>    1.2876</td> <td>    0.602</td> <td>    2.140</td> <td> 0.032</td> <td>    0.108</td> <td>    2.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th>  <td>    0.9943</td> <td>    0.394</td> <td>    2.523</td> <td> 0.012</td> <td>    0.222</td> <td>    1.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th>  <td>   -1.3572</td> <td>    0.359</td> <td>   -3.776</td> <td> 0.000</td> <td>   -2.062</td> <td>   -0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th>  <td>   -1.1242</td> <td>    0.467</td> <td>   -2.406</td> <td> 0.016</td> <td>   -2.040</td> <td>   -0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th>  <td>   -1.4295</td> <td>    0.385</td> <td>   -3.712</td> <td> 0.000</td> <td>   -2.184</td> <td>   -0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th>  <td>   -1.2631</td> <td>    0.403</td> <td>   -3.133</td> <td> 0.002</td> <td>   -2.053</td> <td>   -0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th>  <td>   -0.2997</td> <td>    0.431</td> <td>   -0.696</td> <td> 0.486</td> <td>   -1.144</td> <td>    0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th>  <td>    0.6491</td> <td>    0.378</td> <td>    1.717</td> <td> 0.086</td> <td>   -0.092</td> <td>    1.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th>  <td>    3.3332</td> <td>    0.507</td> <td>    6.572</td> <td> 0.000</td> <td>    2.339</td> <td>    4.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th>  <td>   -1.8873</td> <td>    0.407</td> <td>   -4.641</td> <td> 0.000</td> <td>   -2.684</td> <td>   -1.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th>  <td>    2.6487</td> <td>    0.528</td> <td>    5.012</td> <td> 0.000</td> <td>    1.613</td> <td>    3.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th>  <td>   -0.4267</td> <td>    0.383</td> <td>   -1.115</td> <td> 0.265</td> <td>   -1.176</td> <td>    0.323</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9886\n",
       "Method:                           MLE   Df Model:                          113\n",
       "Date:                Wed, 17 Feb 2021   Pseudo R-squ.:                  0.4936\n",
       "Time:                        14:57:47   Log-Likelihood:                -2865.3\n",
       "converged:                       True   LL-Null:                       -5658.2\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.1348      0.057     37.505      0.000       2.023       2.246\n",
       "x1            -0.6741      0.406     -1.660      0.097      -1.470       0.122\n",
       "x2            -2.0009      0.372     -5.377      0.000      -2.730      -1.272\n",
       "x3            -0.8580      0.348     -2.467      0.014      -1.540      -0.176\n",
       "x4             1.1498      0.397      2.896      0.004       0.372       1.928\n",
       "x5             1.2325      0.416      2.963      0.003       0.417       2.048\n",
       "x6             2.9196      0.461      6.337      0.000       2.017       3.823\n",
       "x7             8.2041      0.712     11.528      0.000       6.809       9.599\n",
       "x8             0.0769      0.384      0.200      0.841      -0.675       0.829\n",
       "x9             4.9761      0.682      7.292      0.000       3.639       6.314\n",
       "x10            0.2289      0.419      0.547      0.585      -0.592       1.050\n",
       "x11            1.2145      0.433      2.803      0.005       0.365       2.064\n",
       "x12           -1.6340      0.415     -3.937      0.000      -2.447      -0.821\n",
       "x13           -0.8741      0.361     -2.421      0.015      -1.582      -0.167\n",
       "x14           -1.8264      0.410     -4.453      0.000      -2.630      -1.023\n",
       "x15           -1.4679      0.378     -3.883      0.000      -2.209      -0.727\n",
       "x16           -0.8294      0.403     -2.056      0.040      -1.620      -0.039\n",
       "x17            4.9991      0.454     11.018      0.000       4.110       5.888\n",
       "x18           -0.6834      0.435     -1.571      0.116      -1.536       0.169\n",
       "x19           -0.2757      0.380     -0.726      0.468      -1.021       0.469\n",
       "x20           -0.4593      0.393     -1.170      0.242      -1.229       0.310\n",
       "x21            0.8176      0.411      1.990      0.047       0.012       1.623\n",
       "x22            0.1994      0.370      0.539      0.590      -0.526       0.925\n",
       "x23           -0.5498      0.380     -1.448      0.147      -1.294       0.194\n",
       "x24            3.8696      0.450      8.597      0.000       2.987       4.752\n",
       "x25            7.1805      0.697     10.302      0.000       5.814       8.547\n",
       "x26            0.8337      0.420      1.985      0.047       0.011       1.657\n",
       "x27           -2.0762      0.379     -5.482      0.000      -2.819      -1.334\n",
       "x28           -0.9839      0.384     -2.563      0.010      -1.736      -0.231\n",
       "x29           -2.1915      0.340     -6.439      0.000      -2.859      -1.524\n",
       "x30           -1.0797      0.361     -2.990      0.003      -1.787      -0.372\n",
       "x31           -0.4986      0.361     -1.380      0.167      -1.207       0.209\n",
       "x32            0.2171      0.392      0.554      0.579      -0.550       0.985\n",
       "x33           -2.1160      0.347     -6.100      0.000      -2.796      -1.436\n",
       "x34            0.1314      0.441      0.298      0.766      -0.734       0.997\n",
       "x35            3.4935      0.426      8.203      0.000       2.659       4.328\n",
       "x36            0.1457      0.380      0.383      0.702      -0.599       0.891\n",
       "x37           -1.3652      0.398     -3.432      0.001      -2.145      -0.586\n",
       "x38           -0.3285      0.359     -0.915      0.360      -1.032       0.375\n",
       "x39            3.0541      0.375      8.136      0.000       2.318       3.790\n",
       "x40           -0.6161      0.380     -1.620      0.105      -1.361       0.129\n",
       "x41            9.3381      0.503     18.571      0.000       8.353      10.324\n",
       "x42           -0.1342      0.442     -0.304      0.761      -1.000       0.731\n",
       "x43           -0.3781      0.361     -1.047      0.295      -1.086       0.330\n",
       "x44           -0.2868      0.437     -0.657      0.511      -1.143       0.569\n",
       "x45           -0.5777      0.501     -1.153      0.249      -1.560       0.405\n",
       "x46            0.0794      0.352      0.226      0.822      -0.610       0.769\n",
       "x47           -0.6242      0.428     -1.458      0.145      -1.463       0.215\n",
       "x48            1.7625      0.473      3.724      0.000       0.835       2.690\n",
       "x49            1.6032      0.475      3.377      0.001       0.673       2.534\n",
       "x50           -0.6888      0.523     -1.318      0.187      -1.713       0.335\n",
       "x51           -1.5593      0.373     -4.180      0.000      -2.291      -0.828\n",
       "x52           -1.3940      0.357     -3.906      0.000      -2.094      -0.694\n",
       "x53            2.7611      0.436      6.328      0.000       1.906       3.616\n",
       "x54            5.7134      0.572      9.984      0.000       4.592       6.835\n",
       "x55            1.0591      0.379      2.797      0.005       0.317       1.801\n",
       "x56           -0.6089      0.471     -1.293      0.196      -1.532       0.314\n",
       "x57            0.0161      0.391      0.041      0.967      -0.749       0.782\n",
       "x58           -0.2279      0.384     -0.593      0.553      -0.981       0.526\n",
       "x59            1.8105      0.490      3.693      0.000       0.850       2.771\n",
       "x60           -3.8810      0.353    -11.005      0.000      -4.572      -3.190\n",
       "x61            2.1438      0.393      5.459      0.000       1.374       2.914\n",
       "x62           -4.7827      0.375    -12.743      0.000      -5.518      -4.047\n",
       "x63           -7.9012      0.445    -17.747      0.000      -8.774      -7.029\n",
       "x64            1.6443      0.561      2.933      0.003       0.546       2.743\n",
       "x65            1.0639      0.428      2.488      0.013       0.226       1.902\n",
       "x66           -1.5643      0.398     -3.929      0.000      -2.345      -0.784\n",
       "x67           -0.4831      0.342     -1.414      0.157      -1.153       0.186\n",
       "x68           -0.8788      0.405     -2.167      0.030      -1.673      -0.084\n",
       "x69           -2.0247      0.379     -5.345      0.000      -2.767      -1.282\n",
       "x70           -1.8683      0.359     -5.211      0.000      -2.571      -1.166\n",
       "x71           -0.5862      0.369     -1.589      0.112      -1.309       0.137\n",
       "x72           -0.0082      0.520     -0.016      0.987      -1.027       1.010\n",
       "x73            0.0284      0.395      0.072      0.943      -0.745       0.802\n",
       "x74           -2.7641      0.334     -8.268      0.000      -3.419      -2.109\n",
       "x75           -1.2452      0.363     -3.432      0.001      -1.956      -0.534\n",
       "x76            0.1721      0.383      0.450      0.653      -0.578       0.922\n",
       "x77            0.2530      0.365      0.694      0.488      -0.462       0.968\n",
       "x78            2.3712      0.403      5.889      0.000       1.582       3.160\n",
       "x79            0.0465      0.405      0.115      0.909      -0.748       0.841\n",
       "x80           -1.9348      0.316     -6.129      0.000      -2.554      -1.316\n",
       "x81           -1.4642      0.484     -3.028      0.002      -2.412      -0.516\n",
       "x82            1.1032      0.436      2.528      0.011       0.248       1.958\n",
       "x83            0.5998      0.406      1.477      0.140      -0.196       1.396\n",
       "x84            0.7346      0.382      1.923      0.054      -0.014       1.483\n",
       "x85            0.6221      0.390      1.595      0.111      -0.142       1.386\n",
       "x86           -0.8785      0.540     -1.628      0.103      -1.936       0.179\n",
       "x87           -2.6816      0.752     -3.564      0.000      -4.156      -1.207\n",
       "x88           -0.0840      0.407     -0.206      0.836      -0.881       0.713\n",
       "x89           -0.9477      0.393     -2.411      0.016      -1.718      -0.177\n",
       "x90           -1.1957      0.399     -2.996      0.003      -1.978      -0.413\n",
       "x91           -1.2974      0.440     -2.952      0.003      -2.159      -0.436\n",
       "x92           -2.8771      0.463     -6.217      0.000      -3.784      -1.970\n",
       "x93            0.3003      0.387      0.776      0.438      -0.459       1.059\n",
       "x94           -2.1412      0.680     -3.148      0.002      -3.474      -0.808\n",
       "x95            0.1729      0.377      0.458      0.647      -0.567       0.912\n",
       "x96            1.6550      0.403      4.109      0.000       0.866       2.444\n",
       "x97           -1.4514      0.384     -3.778      0.000      -2.204      -0.698\n",
       "x98           -0.4775      0.469     -1.018      0.308      -1.396       0.441\n",
       "x99            0.8007      0.410      1.955      0.051      -0.002       1.604\n",
       "x100           1.5401      0.371      4.149      0.000       0.813       2.268\n",
       "x101          -1.8043      0.558     -3.234      0.001      -2.898      -0.711\n",
       "x102           1.2876      0.602      2.140      0.032       0.108       2.467\n",
       "x103           0.9943      0.394      2.523      0.012       0.222       1.767\n",
       "x104          -1.3572      0.359     -3.776      0.000      -2.062      -0.653\n",
       "x105          -1.1242      0.467     -2.406      0.016      -2.040      -0.208\n",
       "x106          -1.4295      0.385     -3.712      0.000      -2.184      -0.675\n",
       "x107          -1.2631      0.403     -3.133      0.002      -2.053      -0.473\n",
       "x108          -0.2997      0.431     -0.696      0.486      -1.144       0.544\n",
       "x109           0.6491      0.378      1.717      0.086      -0.092       1.390\n",
       "x110           3.3332      0.507      6.572      0.000       2.339       4.327\n",
       "x111          -1.8873      0.407     -4.641      0.000      -2.684      -1.090\n",
       "x112           2.6487      0.528      5.012      0.000       1.613       3.684\n",
       "x113          -0.4267      0.383     -1.115      0.265      -1.176       0.323\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train statsmodels logit to view intercept\n",
    "import statsmodels.api as sm\n",
    "# f = feats_norm.A\n",
    "# logit = sm.Logit(data.is_positive.values, sm.add_constant(f))\n",
    "# logit = sm.Logit(data.is_positive.values, sm.add_constant(feats_norm))\n",
    "logit = sm.Logit(data.is_positive.values, sm.add_constant(feats_n))\n",
    "# logit = sm.Logit(data.is_positive.values, feats_n)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not</th>\n",
       "      <th>like</th>\n",
       "      <th>you</th>\n",
       "      <th>great</th>\n",
       "      <th>best</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not  like  you  great  best  is_positive\n",
       "0    1     0    0      0     0            0\n",
       "1    0     1    0      1     0            1\n",
       "2    0     1    1      1     0            1\n",
       "3    1     0    0      0     0            0\n",
       "4    1     0    0      1     1            1\n",
       "5    1     0    0      0     0            0\n",
       "6    1     1    0      0     0            0\n",
       "7    1     0    0      1     1            1\n",
       "8    0     0    0      1     0            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    ], columns=['not', 'like', 'you', 'great', 'best', 'is_positive'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PerfectSeparationError",
     "evalue": "Perfect separation detected, results not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPerfectSeparationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f8527bdd753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1967\u001b[0m                               \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                               \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                               **kwargs)\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m                              \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                              \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m  \u001b[0;31m# It is up to subclasses to wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m                                                        \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                                                        \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                                                        full_output=full_output)\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# NOTE: this is for fit_regularized and should be generalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    225\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                             hess=hessian)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         optim_settings = {'optimizer': method, 'start_params': start_params,\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit_newton\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0miterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mfval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is the negative likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36m_check_perfect_pred\u001b[0;34m(self, params, *args)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 np.allclose(fittedvalues - endog, 0)):\n\u001b[1;32m    210\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Perfect separation detected, results not available\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPerfectSeparationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPerfectSeparationError\u001b[0m: Perfect separation detected, results not available"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df.loc[:, ['not', 'like', 'you', 'great', 'best']]\n",
    "y = df.is_positive\n",
    "logit = sm.Logit(y, X)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load, process Yelp review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583c99f2fc4748fab8c96ae0a5a49f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8021122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "reviews_path = '/data/storyq/yelp_dataset/yelp_academic_dataset_review.json'\n",
    "with open(reviews_path) as f:  # 5.9G\n",
    "    reviews = [json.loads(line) for line in tqdm(f.read().splitlines())]\n",
    "#     for line in f.read().splitlines():\n",
    "#         reviews.append(json.loads(next(f)) for x in tqdm(range(int(1e7)))]\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f49da89b9047098729019614b429af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8021122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {2015: 940603,\n",
       "             2013: 491678,\n",
       "             2011: 302523,\n",
       "             2017: 1217292,\n",
       "             2009: 100760,\n",
       "             2016: 1094154,\n",
       "             2018: 1318054,\n",
       "             2010: 186752,\n",
       "             2014: 702060,\n",
       "             2012: 367367,\n",
       "             2005: 875,\n",
       "             2007: 21130,\n",
       "             2008: 56996,\n",
       "             2006: 5030,\n",
       "             2019: 1215836,\n",
       "             2004: 12})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at years\n",
    "from collections import defaultdict\n",
    "\n",
    "years = defaultdict(int)\n",
    "for review in tqdm(reviews):\n",
    "    year = review['date'][:4]\n",
    "    years[int(year)] += 1\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "year=%{x}<br># reviews=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          2015,
          2013,
          2011,
          2017,
          2009,
          2016,
          2018,
          2010,
          2014,
          2012,
          2005,
          2007,
          2008,
          2006,
          2019,
          2004
         ],
         "xaxis": "x",
         "y": [
          940603,
          491678,
          302523,
          1217292,
          100760,
          1094154,
          1318054,
          186752,
          702060,
          367367,
          875,
          21130,
          56996,
          5030,
          1215836,
          12
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          2003.5,
          2019.5
         ],
         "title": {
          "text": "year"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1387425.2631578948
         ],
         "title": {
          "text": "# reviews"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"10bdfeb7-dbab-4ef2-9f68-666a5ad6dd32\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"10bdfeb7-dbab-4ef2-9f68-666a5ad6dd32\")) {                    Plotly.newPlot(                        \"10bdfeb7-dbab-4ef2-9f68-666a5ad6dd32\",                        [{\"alignmentgroup\": \"True\", \"hovertemplate\": \"year=%{x}<br># reviews=%{y}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [2015, 2013, 2011, 2017, 2009, 2016, 2018, 2010, 2014, 2012, 2005, 2007, 2008, 2006, 2019, 2004], \"xaxis\": \"x\", \"y\": [940603, 491678, 302523, 1217292, 100760, 1094154, 1318054, 186752, 702060, 367367, 875, 21130, 56996, 5030, 1215836, 12], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"year\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"# reviews\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('10bdfeb7-dbab-4ef2-9f68-666a5ad6dd32');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.bar(x=years.keys(),y=years.values(), labels=dict(x='year', y='# reviews'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlines = []\n",
    "count = 1\n",
    "for review in reviews:\n",
    "    if review['stars'] >= 4:\n",
    "        rating = 'positive'\n",
    "    elif review['stars'] <= 2:\n",
    "        rating = 'negative'\n",
    "    else:\n",
    "        continue\n",
    "    outlines.append([review['text'], rating])\n",
    "    count += 1\n",
    "    if count > 10000:\n",
    "        break\n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out condensed data\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(outlines, columns=['review_text', 'rating'])\n",
    "outpath = 'review_sample.csv'\n",
    "data.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process to max 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Amazing food. Glorious bevs. What more could y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Wife and I have been going to Abuelos for year...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I had THE BEST VEGAN Gardein chicken plate wit...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Went there for the first time today and got ve...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>After my second time here I'm still leaving fu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text    rating\n",
       "0     As someone who has worked with many museums, I...  negative\n",
       "1     I am actually horrified this place is still in...  negative\n",
       "2     I love Deagan's. I do. I really do. The atmosp...  positive\n",
       "3     Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  negative\n",
       "4     Oh happy day, finally have a Canes near my cas...  positive\n",
       "...                                                 ...       ...\n",
       "9995  Amazing food. Glorious bevs. What more could y...  positive\n",
       "9996  Wife and I have been going to Abuelos for year...  negative\n",
       "9997  I had THE BEST VEGAN Gardein chicken plate wit...  positive\n",
       "9998  Went there for the first time today and got ve...  positive\n",
       "9999  After my second time here I'm still leaving fu...  positive\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load condensed data\n",
    "import pandas as pd\n",
    "path = '/data/storyq/yelp_dataset/review_sample.csv'\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do sentence tokenization\n",
    "import spacy\n",
    "nlp = spacy.load('en', disable=['tagger', 'parser', 'ner'])\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As someone who has worked with many museums, I was eager to visit this gallery on my most recent trip to Las Vegas. When I saw they would be showing infamous eggs of the House of Faberge from the Virginia Museum of Fine Arts (VMFA), I knew I had to go!\\n\\nTucked away near the gelateria and the garden, the Gallery is pretty much hidden from view. It\\'s what real estate agents would call \"cozy\" or \"charming\" - basically any euphemism for small.\\n\\nThat being said, you can still see wonderful art at a gallery of any size, so why the two *s you ask? Let me tell you:\\n\\n* pricing for this, while relatively inexpensive for a Las Vegas attraction, is completely over the top. For the space and the amount of art you can fit in there, it is a bit much.\\n* it\\'s not kid friendly at all. Seriously, don\\'t bring them.\\n* the security is not trained properly for the show. When the curating and design teams collaborate for exhibitions, there is a definite flow. That means visitors should view the art in a certain sequence, whether it be by historical period or cultural significance (this is how audio guides are usually developed). When I arrived in the gallery I could not tell where to start, and security was certainly not helpful. I was told to \"just look around\" and \"do whatever.\" \\n\\nAt such a *fine* institution, I find the lack of knowledge and respect for the art appalling.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.loc[0, 'review_text']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "As someone who has worked with many museums, I was eager to visit this gallery on my most recent trip to Las Vegas."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>n_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>negative</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>positive</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>negative</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>positive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Amazing food. Glorious bevs. What more could y...</td>\n",
       "      <td>positive</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Wife and I have been going to Abuelos for year...</td>\n",
       "      <td>negative</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I had THE BEST VEGAN Gardein chicken plate wit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Went there for the first time today and got ve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>After my second time here I'm still leaving fu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text    rating  n_sents\n",
       "0     As someone who has worked with many museums, I...  negative       16\n",
       "1     I am actually horrified this place is still in...  negative       25\n",
       "2     I love Deagan's. I do. I really do. The atmosp...  positive       10\n",
       "3     Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  negative        6\n",
       "4     Oh happy day, finally have a Canes near my cas...  positive        8\n",
       "...                                                 ...       ...      ...\n",
       "9995  Amazing food. Glorious bevs. What more could y...  positive       10\n",
       "9996  Wife and I have been going to Abuelos for year...  negative       21\n",
       "9997  I had THE BEST VEGAN Gardein chicken plate wit...  positive        5\n",
       "9998  Went there for the first time today and got ve...  positive        9\n",
       "9999  After my second time here I'm still leaving fu...  positive        5\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['n_sents'] = data['review_text'].map(lambda x: len(list(nlp(x).sents)))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>n_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who has worked with many museums, I was eager to visit this gallery on my most recent trip to Las Vegas. When I saw they would be showing infamous eggs of the House of Faberge from the Virginia Museum of Fine Arts (VMFA), I knew I had to go!\\n\\nTucked away near the gelateria and the garden, the Gallery is pretty much hidden from view. It's what real estate agents would call \"cozy\" or \"charming\" - basically any euphemism for small.\\n\\nThat being said, you can still see wonderful art at a gallery of any size, so why the two *s you ask? Let me tell you:\\n\\n* pricing for this, while relatively inexpensive for a Las Vegas attraction, is completely over the top. For the space and the amount of art you can fit in there, it is a bit much.\\n* it's not kid friendly at all. Seriously, don't bring them.\\n* the security is not trained properly for the show. When the curating and design teams collaborate for exhibitions, there is a definite flow. That means visitors should view the art in a certain sequence, whether it be by historical period or cultural significance (this is how audio guides are usually developed). When I arrived in the gallery I could not tell where to start, and security was certainly not helpful. I was told to \"just look around\" and \"do whatever.\" \\n\\nAt such a *fine* institution, I find the lack of knowledge and respect for the art appalling.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in business. My 3 year old son needed a haircut this past summer and the lure of the $7 kids cut signs got me in the door. We had to wait a few minutes as both stylists were working on people. The decor in this place is total garbage. It is so tacky. The sofa they had at the time was a pleather sofa with giant holes in it. And my son noticed ants crawling all over the floor and the furniture. It was disgusting and I should have walked out then. Actually, I should have turned around and walked out upon entering but I didn't. So the older black male stylist finishes the haircut he was doing and it's our turn. I tell him I want a #2 clipper around the back and sides and then hand cut the top into a standard boys cut. Really freaking simple, right? WRONG! Rather than use the clippers and go up to actually cut the hair, he went down. Using it moving downward doesn't cut hair, it just rubs against it. How does this man who has an alleged cosmetology license not know how to use a set of freaking clippers??? I realized almost immediately that he had no idea what he was doing. No idea at all. After about 10 minutes of watching this guy stumble through it, I said \"you know what? That's fine.\", paid and left. All I wanted to do was get out of that scummy joint and take my son to a real haircut place.\\n\\nBottom line: DO NOT GO HERE. RUN THE OTHER WAY!!!!!</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosphere is cozy and festive. The shrimp tacos and house fries are my standbys. The fries are sometimes good and sometimes great, and the spicy dipping sauce they come with is to die for. The beer list is amazing and the cocktails are great. The prices are mid-level, so it's not a cheap dive you can go to every week, but rather a treat when you do. Try it out. You won't be disappointed!</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" glop;\\n\\nMumbly, unengaged waiter;\\n\\nClueless manager, who seeing us with barely nibbled entrees\\non plates shoved forward for pickup, thanked us\\nperfunctorily for our patronage;\\n\\nWe're from the Texas Hill Country;\\ndown there, we jail critters \\nwho serve up grub this bad,\\nfor their own protection.\\n\\nNever, never, NEVER again\\n(Back to Yard House for real food)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my casa. Yes just as others are griping about the Drive thru is packed just like most of the other canes in the area but I like to go sit down to enjoy my chicken. The cashiers are pleasant and as far as food wise i have yet to receive any funky chicken. The clean up crew zips around the dining area constantly so it's usually well kept. My only gripe is the one fella with Red hair he makes the rounds while cleaning but no smile or personality a few nights ago he tossed the napkins i just put on the table to help go with my meal. After I was done he just reached for my tray no \"excuse me or are you done with that?\"  I realize he's trying to do his job quickly but a little table manners goes along way. That being said still like to grub here and glad that there's finally a Cane's close to me.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Amazing food. Glorious bevs. What more could you want? For a little celebration my boo thang &amp; I decided to finally try this place. We called day of (Thursday) and couldn't make a reservation so we stopped in and were lucky enough to snag a seat at the bar (which is a little tight but I have short legs so it's cool)\\n\\nIf it's your first time I actually recommend sitting here because as a tapas place they try to have you order your food all at once if you are at a table, sitting at the bar is less hurried &amp; gives you chance to order a plate or 2 &amp; decide if you want more.\\n\\nThe staff was super knowledgeable &amp; we especially loved the octopus, cabbage, Jamon iberico de bellota (\"worlds best ham\"). It's pricey but super worth it. Now Go! GO NOW!! See for yourself!</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Wife and I have been going to Abuelos for years, so when we feel like Mexican food there was no other place we considered. We like it so much we drive out of our way to eat there. We frequent Abuelos where ever we find them including but not limited Phoenix, Chandler and Kansas City MO. \\n\\nSo for my wife and I to give a 1 star should hopefully get the attention of the owners. We were extremely disappointed with the food and lack of service during our last few visits to the Chandler location. I would bet on it that the management were not there yesterday during our visit because there was a lack luster attention to service period. \\n\\nWe arrived at 330pm, to find 3 seated tables and a bunch of staff some making eye contact with us as we stood there waiting to be seated. As we stood in the lobby waiting to be seated for 10mins, I turned around to walk out before my wife waved down a waiter who noticed us when we first walked in to seat us. The host was no where to be found but did show as the waiter grabbed the menus. Out of the corner of my eye the host gave our waiter a dirty look, yes I did see that rudeness coming from the host with long black hair. I'm kinda glad someone decided to do her job. But after the food and service, I should have went with my gut feeling and walked out. After all, going to eat at the odd hour has its chance of being served leftover dried out food, but I felt Abuelos was a different place to eat, NOT SO.  \\n\\n\\nThe Pasta La Paz my favorite was lacking sauce, the chicken was dried up leftovers from lunch and had been placed under the salamander to heat then left on the counter to cool to less than room temp when served. My wife's fajitas tacos where not fajita stips but chopped up leftover beef from the lunch. \\n\\nWe pushed out empty drink glasses to the edge of the table for refills which finally got filled after 15mins. We could not wait to get out of there, we are so disappointed since we loved this place so much. \\n\\nWe started noticing this on the last few visits, when we have ate there during off hours. Sadly,  I won't spend another $40 to find out if they have change, that was our purpose for our recent visit. We enjoyed our multiple monthly visits to Abuelos, but that will not be the case any longer. \\n\\nHope this helps improve on what once was a great experiences for us.</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I had THE BEST VEGAN Gardein chicken plate with broccolini. I was blown away!!! The decor is cute! Nicely dimly lit, It was romantic and very chic. I recommend coming if you're a vegan looking for a good dinner!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Went there for the first time today and got very excited. Had heard great things about it so I thought I would  \"go big or go home\". 2 galley boys, french fries, and a shake. I'm stuffed.\\n\\nAnyways, as soon as you pull up the guys run over to your car and take your order. It takes a little longer than that to get your food but they're fairly prompt and it's entertaining to watch the guys in motion. The food is VERY reasonably priced which was great. \\n\\nI come from San Diego, land of the In n' out , so I have my own preferences for fast food but I'll say now that Swenson's gives In n' out a run for it's money. It's that good.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>After my second time here I'm still leaving full of positivity and happiness. Everyone here is very friendly and inviting. This clinic is very affordable even for people with no insurance like me. They are professional but not stiff and they can answer all your questions without fear of judgement. Next time you need a clinic for whatever reason, go here!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       review_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          As someone who has worked with many museums, I was eager to visit this gallery on my most recent trip to Las Vegas. When I saw they would be showing infamous eggs of the House of Faberge from the Virginia Museum of Fine Arts (VMFA), I knew I had to go!\\n\\nTucked away near the gelateria and the garden, the Gallery is pretty much hidden from view. It's what real estate agents would call \"cozy\" or \"charming\" - basically any euphemism for small.\\n\\nThat being said, you can still see wonderful art at a gallery of any size, so why the two *s you ask? Let me tell you:\\n\\n* pricing for this, while relatively inexpensive for a Las Vegas attraction, is completely over the top. For the space and the amount of art you can fit in there, it is a bit much.\\n* it's not kid friendly at all. Seriously, don't bring them.\\n* the security is not trained properly for the show. When the curating and design teams collaborate for exhibitions, there is a definite flow. That means visitors should view the art in a certain sequence, whether it be by historical period or cultural significance (this is how audio guides are usually developed). When I arrived in the gallery I could not tell where to start, and security was certainly not helpful. I was told to \"just look around\" and \"do whatever.\" \\n\\nAt such a *fine* institution, I find the lack of knowledge and respect for the art appalling.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I am actually horrified this place is still in business. My 3 year old son needed a haircut this past summer and the lure of the $7 kids cut signs got me in the door. We had to wait a few minutes as both stylists were working on people. The decor in this place is total garbage. It is so tacky. The sofa they had at the time was a pleather sofa with giant holes in it. And my son noticed ants crawling all over the floor and the furniture. It was disgusting and I should have walked out then. Actually, I should have turned around and walked out upon entering but I didn't. So the older black male stylist finishes the haircut he was doing and it's our turn. I tell him I want a #2 clipper around the back and sides and then hand cut the top into a standard boys cut. Really freaking simple, right? WRONG! Rather than use the clippers and go up to actually cut the hair, he went down. Using it moving downward doesn't cut hair, it just rubs against it. How does this man who has an alleged cosmetology license not know how to use a set of freaking clippers??? I realized almost immediately that he had no idea what he was doing. No idea at all. After about 10 minutes of watching this guy stumble through it, I said \"you know what? That's fine.\", paid and left. All I wanted to do was get out of that scummy joint and take my son to a real haircut place.\\n\\nBottom line: DO NOT GO HERE. RUN THE OTHER WAY!!!!!   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  I love Deagan's. I do. I really do. The atmosphere is cozy and festive. The shrimp tacos and house fries are my standbys. The fries are sometimes good and sometimes great, and the spicy dipping sauce they come with is to die for. The beer list is amazing and the cocktails are great. The prices are mid-level, so it's not a cheap dive you can go to every week, but rather a treat when you do. Try it out. You won't be disappointed!   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Dismal, lukewarm, defrosted-tasting \"TexMex\" glop;\\n\\nMumbly, unengaged waiter;\\n\\nClueless manager, who seeing us with barely nibbled entrees\\non plates shoved forward for pickup, thanked us\\nperfunctorily for our patronage;\\n\\nWe're from the Texas Hill Country;\\ndown there, we jail critters \\nwho serve up grub this bad,\\nfor their own protection.\\n\\nNever, never, NEVER again\\n(Back to Yard House for real food)   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Oh happy day, finally have a Canes near my casa. Yes just as others are griping about the Drive thru is packed just like most of the other canes in the area but I like to go sit down to enjoy my chicken. The cashiers are pleasant and as far as food wise i have yet to receive any funky chicken. The clean up crew zips around the dining area constantly so it's usually well kept. My only gripe is the one fella with Red hair he makes the rounds while cleaning but no smile or personality a few nights ago he tossed the napkins i just put on the table to help go with my meal. After I was done he just reached for my tray no \"excuse me or are you done with that?\"  I realize he's trying to do his job quickly but a little table manners goes along way. That being said still like to grub here and glad that there's finally a Cane's close to me.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...   \n",
       "9995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Amazing food. Glorious bevs. What more could you want? For a little celebration my boo thang & I decided to finally try this place. We called day of (Thursday) and couldn't make a reservation so we stopped in and were lucky enough to snag a seat at the bar (which is a little tight but I have short legs so it's cool)\\n\\nIf it's your first time I actually recommend sitting here because as a tapas place they try to have you order your food all at once if you are at a table, sitting at the bar is less hurried & gives you chance to order a plate or 2 & decide if you want more.\\n\\nThe staff was super knowledgeable & we especially loved the octopus, cabbage, Jamon iberico de bellota (\"worlds best ham\"). It's pricey but super worth it. Now Go! GO NOW!! See for yourself!   \n",
       "9996  Wife and I have been going to Abuelos for years, so when we feel like Mexican food there was no other place we considered. We like it so much we drive out of our way to eat there. We frequent Abuelos where ever we find them including but not limited Phoenix, Chandler and Kansas City MO. \\n\\nSo for my wife and I to give a 1 star should hopefully get the attention of the owners. We were extremely disappointed with the food and lack of service during our last few visits to the Chandler location. I would bet on it that the management were not there yesterday during our visit because there was a lack luster attention to service period. \\n\\nWe arrived at 330pm, to find 3 seated tables and a bunch of staff some making eye contact with us as we stood there waiting to be seated. As we stood in the lobby waiting to be seated for 10mins, I turned around to walk out before my wife waved down a waiter who noticed us when we first walked in to seat us. The host was no where to be found but did show as the waiter grabbed the menus. Out of the corner of my eye the host gave our waiter a dirty look, yes I did see that rudeness coming from the host with long black hair. I'm kinda glad someone decided to do her job. But after the food and service, I should have went with my gut feeling and walked out. After all, going to eat at the odd hour has its chance of being served leftover dried out food, but I felt Abuelos was a different place to eat, NOT SO.  \\n\\n\\nThe Pasta La Paz my favorite was lacking sauce, the chicken was dried up leftovers from lunch and had been placed under the salamander to heat then left on the counter to cool to less than room temp when served. My wife's fajitas tacos where not fajita stips but chopped up leftover beef from the lunch. \\n\\nWe pushed out empty drink glasses to the edge of the table for refills which finally got filled after 15mins. We could not wait to get out of there, we are so disappointed since we loved this place so much. \\n\\nWe started noticing this on the last few visits, when we have ate there during off hours. Sadly,  I won't spend another $40 to find out if they have change, that was our purpose for our recent visit. We enjoyed our multiple monthly visits to Abuelos, but that will not be the case any longer. \\n\\nHope this helps improve on what once was a great experiences for us.   \n",
       "9997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           I had THE BEST VEGAN Gardein chicken plate with broccolini. I was blown away!!! The decor is cute! Nicely dimly lit, It was romantic and very chic. I recommend coming if you're a vegan looking for a good dinner!   \n",
       "9998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Went there for the first time today and got very excited. Had heard great things about it so I thought I would  \"go big or go home\". 2 galley boys, french fries, and a shake. I'm stuffed.\\n\\nAnyways, as soon as you pull up the guys run over to your car and take your order. It takes a little longer than that to get your food but they're fairly prompt and it's entertaining to watch the guys in motion. The food is VERY reasonably priced which was great. \\n\\nI come from San Diego, land of the In n' out , so I have my own preferences for fast food but I'll say now that Swenson's gives In n' out a run for it's money. It's that good.   \n",
       "9999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          After my second time here I'm still leaving full of positivity and happiness. Everyone here is very friendly and inviting. This clinic is very affordable even for people with no insurance like me. They are professional but not stiff and they can answer all your questions without fear of judgement. Next time you need a clinic for whatever reason, go here!   \n",
       "\n",
       "      n_sents  \n",
       "0          16  \n",
       "1          25  \n",
       "2          10  \n",
       "3           6  \n",
       "4           8  \n",
       "...       ...  \n",
       "9995       10  \n",
       "9996       21  \n",
       "9997        5  \n",
       "9998        9  \n",
       "9999        5  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data[['review_text', 'n_sents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4615"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short = data[data['n_sents']<=5]\n",
    "len(short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample Yelp review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    500\n",
       "negative    500\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced sampling between negative and positive ratings\n",
    "sample = pd.concat([short[short['rating']=='positive'].sample(500), short[short['rating']=='negative'].sample(500)])\n",
    "sample = sample.sample(frac=1) # shuffle\n",
    "sample['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    250\n",
       "negative    250\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_train = sample.iloc[:500]\n",
    "short_test = sample.iloc[500:]\n",
    "print(len(short_train))\n",
    "print(len(short_test))\n",
    "short_train['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_train.to_csv('/data/storyq/yelp_dataset/yelp_reviews_short_balanced500_train.csv')\n",
    "short_test.to_csv('/data/storyq/yelp_dataset/yelp_reviews_short_balanced500_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Amazing food. Glorious bevs. What more could y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Wife and I have been going to Abuelos for year...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I had THE BEST VEGAN Gardein chicken plate wit...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Went there for the first time today and got ve...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>After my second time here I'm still leaving fu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text    rating\n",
       "0     As someone who has worked with many museums, I...  negative\n",
       "1     I am actually horrified this place is still in...  negative\n",
       "2     I love Deagan's. I do. I really do. The atmosp...  positive\n",
       "3     Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  negative\n",
       "4     Oh happy day, finally have a Canes near my cas...  positive\n",
       "...                                                 ...       ...\n",
       "9995  Amazing food. Glorious bevs. What more could y...  positive\n",
       "9996  Wife and I have been going to Abuelos for year...  negative\n",
       "9997  I had THE BEST VEGAN Gardein chicken plate wit...  positive\n",
       "9998  Went there for the first time today and got ve...  positive\n",
       "9999  After my second time here I'm still leaving fu...  positive\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load review data\n",
    "import pandas as pd\n",
    "path = 'review_sample10000.csv'\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    500\n",
       "positive    500\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced sampling between negative and positive ratings\n",
    "sample = pd.concat([data[data['rating']=='positive'].sample(500), data[data['rating']=='negative'].sample(500)])\n",
    "sample = sample.sample(frac=1) # shuffle\n",
    "sample['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out\n",
    "outpath = 'yelp_reviews_1000balanced.csv'\n",
    "sample.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Train sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 24634)\n",
      "(1000, 24634)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = int(0.1 * len(data))\n",
    "text_train, text_test, y_train, y_test = train_test_split(data['review_text'], data['rating'], test_size=test_size, random_state=7)\n",
    "corpus = data['review_text']\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "x_train = vectorizer.fit_transform(text_train) # corpus is a list of strings (documents)\n",
    "x_test = vectorizer.transform(text_test) # corpus is a list of strings (documents)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Try on AI experiences data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## From Yelp-trained logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Shiyan</th>\n",
       "      <th>Cansu</th>\n",
       "      <th>Jie</th>\n",
       "      <th>Madeline</th>\n",
       "      <th>Criteria</th>\n",
       "      <th>Other Notes</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siri knows the true meaning of Christmas, offe...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive as it's a good experience although th...</td>\n",
       "      <td>I thought it might be neutral, but then after ...</td>\n",
       "      <td>Started with a negative sacstic crique but lat...</td>\n",
       "      <td>Positive: Humor of experience, and knowing a l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weight towards what sentence?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the most common interactions I have wit...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral as it's a state of fact and it feels l...</td>\n",
       "      <td>I think the participant appreciates the opport...</td>\n",
       "      <td>The writer had a mixture of feelings toward AI...</td>\n",
       "      <td>Negative: Sense of \"too comfortable\" and too g...</td>\n",
       "      <td>If there is a transition from one side to the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I remember one day while I was in graduate sch...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The negative part comes from the writer's frie...</td>\n",
       "      <td>I think it is a funny story and in general, po...</td>\n",
       "      <td>Positive because AI technology seemed to be us...</td>\n",
       "      <td>Positive: The humor involved in pranks; AI as ...</td>\n",
       "      <td>AI technology itself, not the people using it</td>\n",
       "      <td>Humor as positive, involving minor misfortune;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last week, my family was talking about winter ...</td>\n",
       "      <td>Still debating</td>\n",
       "      <td>It tends to be negative as the writer did not ...</td>\n",
       "      <td>Positive; at first the attitude is negative bu...</td>\n",
       "      <td>Negative. Surprised, felt somewhat creepy, end...</td>\n",
       "      <td>Weird coincidence, so mildly negative; people ...</td>\n",
       "      <td>Would this person want to use AI or not? (Cansu)</td>\n",
       "      <td>Making inferences is a human thing; consistent...</td>\n",
       "      <td>No agreement on last quote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My Apple watch counts each hour in which I hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Would this person have this experience again? ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One of the most frustrating encounters with AI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Facebook tries to be helpful.  Whenever I am o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yesterday, I chatted with Emma, an agent that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I, like most people, use Google search several...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I love using navigation apps to get places. Es...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I love the youtube smart playlists.  At a cert...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Last month, I had a discussion with my friends...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My phone's AI has figured out that the first t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I do not remember the years that we have start...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text           Label  \\\n",
       "0   Siri knows the true meaning of Christmas, offe...        Positive   \n",
       "1   One of the most common interactions I have wit...        Positive   \n",
       "2   I remember one day while I was in graduate sch...        Positive   \n",
       "3   Last week, my family was talking about winter ...  Still debating   \n",
       "4   My Apple watch counts each hour in which I hav...             NaN   \n",
       "5   One of the most frustrating encounters with AI...             NaN   \n",
       "6   Facebook tries to be helpful.  Whenever I am o...             NaN   \n",
       "7   Yesterday, I chatted with Emma, an agent that ...             NaN   \n",
       "8   I, like most people, use Google search several...             NaN   \n",
       "9   I love using navigation apps to get places. Es...             NaN   \n",
       "10  I love the youtube smart playlists.  At a cert...             NaN   \n",
       "11  Last month, I had a discussion with my friends...             NaN   \n",
       "12  My phone's AI has figured out that the first t...             NaN   \n",
       "13  I do not remember the years that we have start...             NaN   \n",
       "\n",
       "                                               Shiyan  \\\n",
       "0   Positive as it's a good experience although th...   \n",
       "1   Neutral as it's a state of fact and it feels l...   \n",
       "2   The negative part comes from the writer's frie...   \n",
       "3   It tends to be negative as the writer did not ...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                                Cansu  \\\n",
       "0   I thought it might be neutral, but then after ...   \n",
       "1   I think the participant appreciates the opport...   \n",
       "2   I think it is a funny story and in general, po...   \n",
       "3   Positive; at first the attitude is negative bu...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                                  Jie  \\\n",
       "0   Started with a negative sacstic crique but lat...   \n",
       "1   The writer had a mixture of feelings toward AI...   \n",
       "2   Positive because AI technology seemed to be us...   \n",
       "3   Negative. Surprised, felt somewhat creepy, end...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                             Madeline  \\\n",
       "0   Positive: Humor of experience, and knowing a l...   \n",
       "1   Negative: Sense of \"too comfortable\" and too g...   \n",
       "2   Positive: The humor involved in pranks; AI as ...   \n",
       "3   Weird coincidence, so mildly negative; people ...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                             Criteria  \\\n",
       "0                                                 NaN   \n",
       "1   If there is a transition from one side to the ...   \n",
       "2       AI technology itself, not the people using it   \n",
       "3    Would this person want to use AI or not? (Cansu)   \n",
       "4   Would this person have this experience again? ...   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                          Other Notes  \\\n",
       "0                       Weight towards what sentence?   \n",
       "1                                                 NaN   \n",
       "2   Humor as positive, involving minor misfortune;...   \n",
       "3   Making inferences is a human thing; consistent...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                    Unnamed: 8  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3   No agreement on last quote  \n",
       "4                          NaN  \n",
       "5                          NaN  \n",
       "6                          NaN  \n",
       "7                          NaN  \n",
       "8                          NaN  \n",
       "9                          NaN  \n",
       "10                         NaN  \n",
       "11                         NaN  \n",
       "12                         NaN  \n",
       "13                         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '/home/mamille2/storyq/ai_experiences.csv'\n",
    "path = 'ai_experiences.csv'\n",
    "experiences = pd.read_csv(path)\n",
    "experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 24634)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = experiences['Text']\n",
    "bow = vectorizer.transform(corpus) # corpus is a list of strings (documents)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>yelp10k_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siri knows the true meaning of Christmas, offe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the most common interactions I have wit...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I remember one day while I was in graduate sch...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last week, my family was talking about winter ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My Apple watch counts each hour in which I hav...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One of the most frustrating encounters with AI...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Facebook tries to be helpful.  Whenever I am o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yesterday, I chatted with Emma, an agent that ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I, like most people, use Google search several...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I love using navigation apps to get places. Es...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I love the youtube smart playlists.  At a cert...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Last month, I had a discussion with my friends...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My phone's AI has figured out that the first t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I do not remember the years that we have start...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text yelp10k_classifier\n",
       "0   Siri knows the true meaning of Christmas, offe...           positive\n",
       "1   One of the most common interactions I have wit...           positive\n",
       "2   I remember one day while I was in graduate sch...           negative\n",
       "3   Last week, my family was talking about winter ...           positive\n",
       "4   My Apple watch counts each hour in which I hav...           negative\n",
       "5   One of the most frustrating encounters with AI...           positive\n",
       "6   Facebook tries to be helpful.  Whenever I am o...           positive\n",
       "7   Yesterday, I chatted with Emma, an agent that ...           negative\n",
       "8   I, like most people, use Google search several...           positive\n",
       "9   I love using navigation apps to get places. Es...           positive\n",
       "10  I love the youtube smart playlists.  At a cert...           positive\n",
       "11  Last month, I had a discussion with my friends...           positive\n",
       "12  My phone's AI has figured out that the first t...           positive\n",
       "13  I do not remember the years that we have start...           negative"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences['yelp10k_classifier'] = clf.predict(bow)\n",
    "experiences.loc[:, ['Text', 'yelp10k_classifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     positive\n",
       "1     positive\n",
       "2     negative\n",
       "3     positive\n",
       "4     negative\n",
       "5     positive\n",
       "6     positive\n",
       "7     negative\n",
       "8     positive\n",
       "9     positive\n",
       "10    positive\n",
       "11    positive\n",
       "12    positive\n",
       "13    negative\n",
       "Name: yelp10k_classifier, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences['yelp10k_classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def print_top_features(vectorizer, clf, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    top_indices = np.argsort(clf.coef_[0])[-1*n:]\n",
    "    print(\"\\n\".join(reversed([feature_names[j] for j in top_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def print_bottom_features(vectorizer, clf, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    top_indices = np.argsort(clf.coef_[0])[:n]\n",
    "    print(\"\\n\".join(reversed([feature_names[j] for j in top_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n",
      "amazing\n",
      "delicious\n",
      "love\n",
      "best\n",
      "and\n",
      "awesome\n",
      "definitely\n",
      "friendly\n",
      "excellent\n",
      "always\n",
      "perfect\n",
      "good\n",
      "nice\n",
      "little\n",
      "loved\n",
      "fantastic\n",
      "very\n",
      "highly\n",
      "with\n"
     ]
    }
   ],
   "source": [
    "print_top_features(vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow\n",
      "then\n",
      "won\n",
      "left\n",
      "poor\n",
      "nothing\n",
      "money\n",
      "bad\n",
      "over\n",
      "asked\n",
      "told\n",
      "ok\n",
      "bland\n",
      "horrible\n",
      "never\n",
      "terrible\n",
      "rude\n",
      "worst\n",
      "no\n",
      "not\n"
     ]
    }
   ],
   "source": [
    "print_bottom_features(vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_informative_features(features_vectorizer, model, model_name, data_dirpath, n=10000):\n",
    "    feats_index2name = {v: k for k, v in features_vectorizer.vocabulary_.items()}\n",
    "    feature_weights = model.coef_[0]\n",
    "    \n",
    "    top_indices = np.argsort(feature_weights)[-1*n:]\n",
    "    top_weights = np.sort(feature_weights)[-1*n:]\n",
    "    bottom_indices = np.argsort(feature_weights)[:n]\n",
    "    bottom_weights = np.sort(feature_weights)[:n]\n",
    "\n",
    "    nontag_lines = [] # to sort and print\n",
    "    lines = [] # to sort and print\n",
    "    \n",
    "    for i, (j, w) in enumerate(zip(reversed(top_indices), reversed(top_weights))):\n",
    "        feature_name = feats_index2name[j]\n",
    "        if not feature_name.startswith('tag'):\n",
    "            nontag_lines.append([i, feature_name, w, abs(w)])\n",
    "#             print(f\"{i}\\t{feature_name}\\t{w: .3f}\")\n",
    "        lines.append([i, feature_name, w, abs(w)])\n",
    "    \n",
    "    for i, (j, w) in enumerate(zip(bottom_indices, bottom_weights)):\n",
    "        feature_name = feats_index2name[j]\n",
    "        if not feature_name.startswith('tag'):\n",
    "            nontag_lines.append([i, feature_name, w, abs(w)])\n",
    "        lines.append([i, feature_name, w, abs(w)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## From NLTK SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy' has no attribute '_lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8838b6bcfd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/nltk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Import top-level functionality into top-level namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollocations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatstruct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# these two unused imports are referenced in collocations.doctest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m from nltk.metrics import (\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mContingencyMeasures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mBigramAssocMeasures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/nltk/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from nltk.metrics.scores import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/nltk/metrics/scores.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbetai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbetai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \"\"\"\n\u001b[0;32m--> 388\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                     rv_frozen)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# for root finding for continuous distribution ppf, and max likelihood estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/optimize/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    385\u001b[0m \"\"\"\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_minimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                          \u001b[0mline_search_wolfe2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mline_search\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                          LineSearchWarning)\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_numdiff\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapprox_derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetfullargspec_no_self\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMapWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsc_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_group_columns\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgroup_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/sparse/linalg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \"\"\"\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0misolve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdsolve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/sparse/linalg/isolve/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#from info import __doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0miterative\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mminres\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlgmres\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlgmres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/sparse/linalg/isolve/iterative.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m                )\n\u001b[1;32m    149\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mnon_reentrant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mbicg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpostprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/_lib/_threadsafety.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s is not re-entrant\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReentrancyLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/_lib/_threadsafety.py\u001b[0m in \u001b[0;36mdecorate\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy' has no attribute '_lib'"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
