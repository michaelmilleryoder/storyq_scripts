{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Investigate logistic regression intercept with text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try normalization on Yelp review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Amazing food. Glorious bevs. What more could y...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Wife and I have been going to Abuelos for year...</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I had THE BEST VEGAN Gardein chicken plate wit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Went there for the first time today and got ve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>After my second time here I'm still leaving fu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text    rating  is_positive\n",
       "0     As someone who has worked with many museums, I...  negative        False\n",
       "1     I am actually horrified this place is still in...  negative        False\n",
       "2     I love Deagan's. I do. I really do. The atmosp...  positive         True\n",
       "3     Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  negative        False\n",
       "4     Oh happy day, finally have a Canes near my cas...  positive         True\n",
       "...                                                 ...       ...          ...\n",
       "9995  Amazing food. Glorious bevs. What more could y...  positive         True\n",
       "9996  Wife and I have been going to Abuelos for year...  negative        False\n",
       "9997  I had THE BEST VEGAN Gardein chicken plate wit...  positive         True\n",
       "9998  Went there for the first time today and got ve...  positive         True\n",
       "9999  After my second time here I'm still leaving fu...  positive         True\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load review data\n",
    "import pandas as pd\n",
    "path = '/data/storyq/yelp_dataset/review_sample.csv'\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "data['is_positive'] = data.rating.map(lambda x: True if x=='positive' else False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 113)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = data['review_text']\n",
    "vectorizer = CountVectorizer(min_df=1000)\n",
    "feats = vectorizer.fit_transform(corpus) # corpus is a list of strings (documents)\n",
    "print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38697222, -0.34774403, -0.32728854, ...,  2.59369408,\n",
       "         2.0023615 , -0.35231082],\n",
       "       [ 1.27171711,  1.68942076, -0.32728854, ..., -0.42996421,\n",
       "         0.09819169, -0.35231082],\n",
       "       [-0.38697222, -0.34774403, -0.32728854, ..., -0.42996421,\n",
       "         1.36763823, -0.35231082],\n",
       "       ...,\n",
       "       [-0.38697222, -0.34774403, -0.32728854, ..., -0.42996421,\n",
       "         0.09819169, -0.35231082],\n",
       "       [ 1.27171711, -0.34774403, -0.32728854, ...,  1.08186493,\n",
       "         0.09819169,  4.61214413],\n",
       "       [-0.38697222,  1.68942076, -0.32728854, ..., -0.42996421,\n",
       "         0.09819169,  1.3025075 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "# scaler = StandardScaler(with_mean=False)\n",
    "scaler = StandardScaler()\n",
    "# feats_norm = scaler.fit_transform(sm.add_constant(feats.A))\n",
    "feats_norm = scaler.fit_transform(feats.A)\n",
    "feats_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02920484, -0.02624428, -0.0247005 , ...,  0.19574638,\n",
       "         0.15111844, -0.02658894],\n",
       "       [ 0.09131528,  0.12130837, -0.02350086, ..., -0.03087345,\n",
       "         0.00705063, -0.02529758],\n",
       "       [-0.04045508, -0.03635406, -0.03421559, ..., -0.04494957,\n",
       "         0.14297644, -0.03683148],\n",
       "       ...,\n",
       "       [-0.06845064, -0.06151166, -0.05789333, ..., -0.0760554 ,\n",
       "         0.01736891, -0.06231947],\n",
       "       [ 0.1168897 , -0.03196284, -0.03008268, ...,  0.09943946,\n",
       "         0.00902528,  0.42392457],\n",
       "       [-0.04767385,  0.20813173, -0.040321  , ..., -0.05297034,\n",
       "         0.01209693,  0.16046514]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "# feats_n = normalize(sm.add_constant(feats.A))\n",
    "feats_n = normalize(feats_norm)\n",
    "feats_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286534\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  9886</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>   113</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 17 Feb 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.4936</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:57:47</td>     <th>  Log-Likelihood:    </th> <td> -2865.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -5658.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.1348</td> <td>    0.057</td> <td>   37.505</td> <td> 0.000</td> <td>    2.023</td> <td>    2.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.6741</td> <td>    0.406</td> <td>   -1.660</td> <td> 0.097</td> <td>   -1.470</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -2.0009</td> <td>    0.372</td> <td>   -5.377</td> <td> 0.000</td> <td>   -2.730</td> <td>   -1.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.8580</td> <td>    0.348</td> <td>   -2.467</td> <td> 0.014</td> <td>   -1.540</td> <td>   -0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.1498</td> <td>    0.397</td> <td>    2.896</td> <td> 0.004</td> <td>    0.372</td> <td>    1.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.2325</td> <td>    0.416</td> <td>    2.963</td> <td> 0.003</td> <td>    0.417</td> <td>    2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    2.9196</td> <td>    0.461</td> <td>    6.337</td> <td> 0.000</td> <td>    2.017</td> <td>    3.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    8.2041</td> <td>    0.712</td> <td>   11.528</td> <td> 0.000</td> <td>    6.809</td> <td>    9.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0769</td> <td>    0.384</td> <td>    0.200</td> <td> 0.841</td> <td>   -0.675</td> <td>    0.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    4.9761</td> <td>    0.682</td> <td>    7.292</td> <td> 0.000</td> <td>    3.639</td> <td>    6.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.2289</td> <td>    0.419</td> <td>    0.547</td> <td> 0.585</td> <td>   -0.592</td> <td>    1.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    1.2145</td> <td>    0.433</td> <td>    2.803</td> <td> 0.005</td> <td>    0.365</td> <td>    2.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -1.6340</td> <td>    0.415</td> <td>   -3.937</td> <td> 0.000</td> <td>   -2.447</td> <td>   -0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.8741</td> <td>    0.361</td> <td>   -2.421</td> <td> 0.015</td> <td>   -1.582</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -1.8264</td> <td>    0.410</td> <td>   -4.453</td> <td> 0.000</td> <td>   -2.630</td> <td>   -1.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -1.4679</td> <td>    0.378</td> <td>   -3.883</td> <td> 0.000</td> <td>   -2.209</td> <td>   -0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.8294</td> <td>    0.403</td> <td>   -2.056</td> <td> 0.040</td> <td>   -1.620</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    4.9991</td> <td>    0.454</td> <td>   11.018</td> <td> 0.000</td> <td>    4.110</td> <td>    5.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.6834</td> <td>    0.435</td> <td>   -1.571</td> <td> 0.116</td> <td>   -1.536</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.2757</td> <td>    0.380</td> <td>   -0.726</td> <td> 0.468</td> <td>   -1.021</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.4593</td> <td>    0.393</td> <td>   -1.170</td> <td> 0.242</td> <td>   -1.229</td> <td>    0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.8176</td> <td>    0.411</td> <td>    1.990</td> <td> 0.047</td> <td>    0.012</td> <td>    1.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.1994</td> <td>    0.370</td> <td>    0.539</td> <td> 0.590</td> <td>   -0.526</td> <td>    0.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.5498</td> <td>    0.380</td> <td>   -1.448</td> <td> 0.147</td> <td>   -1.294</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    3.8696</td> <td>    0.450</td> <td>    8.597</td> <td> 0.000</td> <td>    2.987</td> <td>    4.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    7.1805</td> <td>    0.697</td> <td>   10.302</td> <td> 0.000</td> <td>    5.814</td> <td>    8.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.8337</td> <td>    0.420</td> <td>    1.985</td> <td> 0.047</td> <td>    0.011</td> <td>    1.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -2.0762</td> <td>    0.379</td> <td>   -5.482</td> <td> 0.000</td> <td>   -2.819</td> <td>   -1.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.9839</td> <td>    0.384</td> <td>   -2.563</td> <td> 0.010</td> <td>   -1.736</td> <td>   -0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -2.1915</td> <td>    0.340</td> <td>   -6.439</td> <td> 0.000</td> <td>   -2.859</td> <td>   -1.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -1.0797</td> <td>    0.361</td> <td>   -2.990</td> <td> 0.003</td> <td>   -1.787</td> <td>   -0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.4986</td> <td>    0.361</td> <td>   -1.380</td> <td> 0.167</td> <td>   -1.207</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.2171</td> <td>    0.392</td> <td>    0.554</td> <td> 0.579</td> <td>   -0.550</td> <td>    0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -2.1160</td> <td>    0.347</td> <td>   -6.100</td> <td> 0.000</td> <td>   -2.796</td> <td>   -1.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.1314</td> <td>    0.441</td> <td>    0.298</td> <td> 0.766</td> <td>   -0.734</td> <td>    0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    3.4935</td> <td>    0.426</td> <td>    8.203</td> <td> 0.000</td> <td>    2.659</td> <td>    4.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.1457</td> <td>    0.380</td> <td>    0.383</td> <td> 0.702</td> <td>   -0.599</td> <td>    0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -1.3652</td> <td>    0.398</td> <td>   -3.432</td> <td> 0.001</td> <td>   -2.145</td> <td>   -0.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.3285</td> <td>    0.359</td> <td>   -0.915</td> <td> 0.360</td> <td>   -1.032</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    3.0541</td> <td>    0.375</td> <td>    8.136</td> <td> 0.000</td> <td>    2.318</td> <td>    3.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.6161</td> <td>    0.380</td> <td>   -1.620</td> <td> 0.105</td> <td>   -1.361</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    9.3381</td> <td>    0.503</td> <td>   18.571</td> <td> 0.000</td> <td>    8.353</td> <td>   10.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1342</td> <td>    0.442</td> <td>   -0.304</td> <td> 0.761</td> <td>   -1.000</td> <td>    0.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.3781</td> <td>    0.361</td> <td>   -1.047</td> <td> 0.295</td> <td>   -1.086</td> <td>    0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.2868</td> <td>    0.437</td> <td>   -0.657</td> <td> 0.511</td> <td>   -1.143</td> <td>    0.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.5777</td> <td>    0.501</td> <td>   -1.153</td> <td> 0.249</td> <td>   -1.560</td> <td>    0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.0794</td> <td>    0.352</td> <td>    0.226</td> <td> 0.822</td> <td>   -0.610</td> <td>    0.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.6242</td> <td>    0.428</td> <td>   -1.458</td> <td> 0.145</td> <td>   -1.463</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    1.7625</td> <td>    0.473</td> <td>    3.724</td> <td> 0.000</td> <td>    0.835</td> <td>    2.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    1.6032</td> <td>    0.475</td> <td>    3.377</td> <td> 0.001</td> <td>    0.673</td> <td>    2.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.6888</td> <td>    0.523</td> <td>   -1.318</td> <td> 0.187</td> <td>   -1.713</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -1.5593</td> <td>    0.373</td> <td>   -4.180</td> <td> 0.000</td> <td>   -2.291</td> <td>   -0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -1.3940</td> <td>    0.357</td> <td>   -3.906</td> <td> 0.000</td> <td>   -2.094</td> <td>   -0.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>    2.7611</td> <td>    0.436</td> <td>    6.328</td> <td> 0.000</td> <td>    1.906</td> <td>    3.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>    5.7134</td> <td>    0.572</td> <td>    9.984</td> <td> 0.000</td> <td>    4.592</td> <td>    6.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>    1.0591</td> <td>    0.379</td> <td>    2.797</td> <td> 0.005</td> <td>    0.317</td> <td>    1.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>   -0.6089</td> <td>    0.471</td> <td>   -1.293</td> <td> 0.196</td> <td>   -1.532</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>    0.0161</td> <td>    0.391</td> <td>    0.041</td> <td> 0.967</td> <td>   -0.749</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>   -0.2279</td> <td>    0.384</td> <td>   -0.593</td> <td> 0.553</td> <td>   -0.981</td> <td>    0.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>    1.8105</td> <td>    0.490</td> <td>    3.693</td> <td> 0.000</td> <td>    0.850</td> <td>    2.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>   -3.8810</td> <td>    0.353</td> <td>  -11.005</td> <td> 0.000</td> <td>   -4.572</td> <td>   -3.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>    2.1438</td> <td>    0.393</td> <td>    5.459</td> <td> 0.000</td> <td>    1.374</td> <td>    2.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>   -4.7827</td> <td>    0.375</td> <td>  -12.743</td> <td> 0.000</td> <td>   -5.518</td> <td>   -4.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>   -7.9012</td> <td>    0.445</td> <td>  -17.747</td> <td> 0.000</td> <td>   -8.774</td> <td>   -7.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>    1.6443</td> <td>    0.561</td> <td>    2.933</td> <td> 0.003</td> <td>    0.546</td> <td>    2.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>    1.0639</td> <td>    0.428</td> <td>    2.488</td> <td> 0.013</td> <td>    0.226</td> <td>    1.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>   -1.5643</td> <td>    0.398</td> <td>   -3.929</td> <td> 0.000</td> <td>   -2.345</td> <td>   -0.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>   -0.4831</td> <td>    0.342</td> <td>   -1.414</td> <td> 0.157</td> <td>   -1.153</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>   <td>   -0.8788</td> <td>    0.405</td> <td>   -2.167</td> <td> 0.030</td> <td>   -1.673</td> <td>   -0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>   <td>   -2.0247</td> <td>    0.379</td> <td>   -5.345</td> <td> 0.000</td> <td>   -2.767</td> <td>   -1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>   <td>   -1.8683</td> <td>    0.359</td> <td>   -5.211</td> <td> 0.000</td> <td>   -2.571</td> <td>   -1.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>   <td>   -0.5862</td> <td>    0.369</td> <td>   -1.589</td> <td> 0.112</td> <td>   -1.309</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>   <td>   -0.0082</td> <td>    0.520</td> <td>   -0.016</td> <td> 0.987</td> <td>   -1.027</td> <td>    1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>   <td>    0.0284</td> <td>    0.395</td> <td>    0.072</td> <td> 0.943</td> <td>   -0.745</td> <td>    0.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>   <td>   -2.7641</td> <td>    0.334</td> <td>   -8.268</td> <td> 0.000</td> <td>   -3.419</td> <td>   -2.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>   <td>   -1.2452</td> <td>    0.363</td> <td>   -3.432</td> <td> 0.001</td> <td>   -1.956</td> <td>   -0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>   <td>    0.1721</td> <td>    0.383</td> <td>    0.450</td> <td> 0.653</td> <td>   -0.578</td> <td>    0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>   <td>    0.2530</td> <td>    0.365</td> <td>    0.694</td> <td> 0.488</td> <td>   -0.462</td> <td>    0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>   <td>    2.3712</td> <td>    0.403</td> <td>    5.889</td> <td> 0.000</td> <td>    1.582</td> <td>    3.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>   <td>    0.0465</td> <td>    0.405</td> <td>    0.115</td> <td> 0.909</td> <td>   -0.748</td> <td>    0.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>   <td>   -1.9348</td> <td>    0.316</td> <td>   -6.129</td> <td> 0.000</td> <td>   -2.554</td> <td>   -1.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>   <td>   -1.4642</td> <td>    0.484</td> <td>   -3.028</td> <td> 0.002</td> <td>   -2.412</td> <td>   -0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>   <td>    1.1032</td> <td>    0.436</td> <td>    2.528</td> <td> 0.011</td> <td>    0.248</td> <td>    1.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>   <td>    0.5998</td> <td>    0.406</td> <td>    1.477</td> <td> 0.140</td> <td>   -0.196</td> <td>    1.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>   <td>    0.7346</td> <td>    0.382</td> <td>    1.923</td> <td> 0.054</td> <td>   -0.014</td> <td>    1.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>   <td>    0.6221</td> <td>    0.390</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.142</td> <td>    1.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>   <td>   -0.8785</td> <td>    0.540</td> <td>   -1.628</td> <td> 0.103</td> <td>   -1.936</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>   <td>   -2.6816</td> <td>    0.752</td> <td>   -3.564</td> <td> 0.000</td> <td>   -4.156</td> <td>   -1.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>   <td>   -0.0840</td> <td>    0.407</td> <td>   -0.206</td> <td> 0.836</td> <td>   -0.881</td> <td>    0.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>   <td>   -0.9477</td> <td>    0.393</td> <td>   -2.411</td> <td> 0.016</td> <td>   -1.718</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>   <td>   -1.1957</td> <td>    0.399</td> <td>   -2.996</td> <td> 0.003</td> <td>   -1.978</td> <td>   -0.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>   <td>   -1.2974</td> <td>    0.440</td> <td>   -2.952</td> <td> 0.003</td> <td>   -2.159</td> <td>   -0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>   <td>   -2.8771</td> <td>    0.463</td> <td>   -6.217</td> <td> 0.000</td> <td>   -3.784</td> <td>   -1.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>   <td>    0.3003</td> <td>    0.387</td> <td>    0.776</td> <td> 0.438</td> <td>   -0.459</td> <td>    1.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>   <td>   -2.1412</td> <td>    0.680</td> <td>   -3.148</td> <td> 0.002</td> <td>   -3.474</td> <td>   -0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>   <td>    0.1729</td> <td>    0.377</td> <td>    0.458</td> <td> 0.647</td> <td>   -0.567</td> <td>    0.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>   <td>    1.6550</td> <td>    0.403</td> <td>    4.109</td> <td> 0.000</td> <td>    0.866</td> <td>    2.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>   <td>   -1.4514</td> <td>    0.384</td> <td>   -3.778</td> <td> 0.000</td> <td>   -2.204</td> <td>   -0.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>   <td>   -0.4775</td> <td>    0.469</td> <td>   -1.018</td> <td> 0.308</td> <td>   -1.396</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>   <td>    0.8007</td> <td>    0.410</td> <td>    1.955</td> <td> 0.051</td> <td>   -0.002</td> <td>    1.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th>  <td>    1.5401</td> <td>    0.371</td> <td>    4.149</td> <td> 0.000</td> <td>    0.813</td> <td>    2.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th>  <td>   -1.8043</td> <td>    0.558</td> <td>   -3.234</td> <td> 0.001</td> <td>   -2.898</td> <td>   -0.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th>  <td>    1.2876</td> <td>    0.602</td> <td>    2.140</td> <td> 0.032</td> <td>    0.108</td> <td>    2.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th>  <td>    0.9943</td> <td>    0.394</td> <td>    2.523</td> <td> 0.012</td> <td>    0.222</td> <td>    1.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th>  <td>   -1.3572</td> <td>    0.359</td> <td>   -3.776</td> <td> 0.000</td> <td>   -2.062</td> <td>   -0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th>  <td>   -1.1242</td> <td>    0.467</td> <td>   -2.406</td> <td> 0.016</td> <td>   -2.040</td> <td>   -0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th>  <td>   -1.4295</td> <td>    0.385</td> <td>   -3.712</td> <td> 0.000</td> <td>   -2.184</td> <td>   -0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th>  <td>   -1.2631</td> <td>    0.403</td> <td>   -3.133</td> <td> 0.002</td> <td>   -2.053</td> <td>   -0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th>  <td>   -0.2997</td> <td>    0.431</td> <td>   -0.696</td> <td> 0.486</td> <td>   -1.144</td> <td>    0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th>  <td>    0.6491</td> <td>    0.378</td> <td>    1.717</td> <td> 0.086</td> <td>   -0.092</td> <td>    1.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th>  <td>    3.3332</td> <td>    0.507</td> <td>    6.572</td> <td> 0.000</td> <td>    2.339</td> <td>    4.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th>  <td>   -1.8873</td> <td>    0.407</td> <td>   -4.641</td> <td> 0.000</td> <td>   -2.684</td> <td>   -1.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th>  <td>    2.6487</td> <td>    0.528</td> <td>    5.012</td> <td> 0.000</td> <td>    1.613</td> <td>    3.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th>  <td>   -0.4267</td> <td>    0.383</td> <td>   -1.115</td> <td> 0.265</td> <td>   -1.176</td> <td>    0.323</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9886\n",
       "Method:                           MLE   Df Model:                          113\n",
       "Date:                Wed, 17 Feb 2021   Pseudo R-squ.:                  0.4936\n",
       "Time:                        14:57:47   Log-Likelihood:                -2865.3\n",
       "converged:                       True   LL-Null:                       -5658.2\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.1348      0.057     37.505      0.000       2.023       2.246\n",
       "x1            -0.6741      0.406     -1.660      0.097      -1.470       0.122\n",
       "x2            -2.0009      0.372     -5.377      0.000      -2.730      -1.272\n",
       "x3            -0.8580      0.348     -2.467      0.014      -1.540      -0.176\n",
       "x4             1.1498      0.397      2.896      0.004       0.372       1.928\n",
       "x5             1.2325      0.416      2.963      0.003       0.417       2.048\n",
       "x6             2.9196      0.461      6.337      0.000       2.017       3.823\n",
       "x7             8.2041      0.712     11.528      0.000       6.809       9.599\n",
       "x8             0.0769      0.384      0.200      0.841      -0.675       0.829\n",
       "x9             4.9761      0.682      7.292      0.000       3.639       6.314\n",
       "x10            0.2289      0.419      0.547      0.585      -0.592       1.050\n",
       "x11            1.2145      0.433      2.803      0.005       0.365       2.064\n",
       "x12           -1.6340      0.415     -3.937      0.000      -2.447      -0.821\n",
       "x13           -0.8741      0.361     -2.421      0.015      -1.582      -0.167\n",
       "x14           -1.8264      0.410     -4.453      0.000      -2.630      -1.023\n",
       "x15           -1.4679      0.378     -3.883      0.000      -2.209      -0.727\n",
       "x16           -0.8294      0.403     -2.056      0.040      -1.620      -0.039\n",
       "x17            4.9991      0.454     11.018      0.000       4.110       5.888\n",
       "x18           -0.6834      0.435     -1.571      0.116      -1.536       0.169\n",
       "x19           -0.2757      0.380     -0.726      0.468      -1.021       0.469\n",
       "x20           -0.4593      0.393     -1.170      0.242      -1.229       0.310\n",
       "x21            0.8176      0.411      1.990      0.047       0.012       1.623\n",
       "x22            0.1994      0.370      0.539      0.590      -0.526       0.925\n",
       "x23           -0.5498      0.380     -1.448      0.147      -1.294       0.194\n",
       "x24            3.8696      0.450      8.597      0.000       2.987       4.752\n",
       "x25            7.1805      0.697     10.302      0.000       5.814       8.547\n",
       "x26            0.8337      0.420      1.985      0.047       0.011       1.657\n",
       "x27           -2.0762      0.379     -5.482      0.000      -2.819      -1.334\n",
       "x28           -0.9839      0.384     -2.563      0.010      -1.736      -0.231\n",
       "x29           -2.1915      0.340     -6.439      0.000      -2.859      -1.524\n",
       "x30           -1.0797      0.361     -2.990      0.003      -1.787      -0.372\n",
       "x31           -0.4986      0.361     -1.380      0.167      -1.207       0.209\n",
       "x32            0.2171      0.392      0.554      0.579      -0.550       0.985\n",
       "x33           -2.1160      0.347     -6.100      0.000      -2.796      -1.436\n",
       "x34            0.1314      0.441      0.298      0.766      -0.734       0.997\n",
       "x35            3.4935      0.426      8.203      0.000       2.659       4.328\n",
       "x36            0.1457      0.380      0.383      0.702      -0.599       0.891\n",
       "x37           -1.3652      0.398     -3.432      0.001      -2.145      -0.586\n",
       "x38           -0.3285      0.359     -0.915      0.360      -1.032       0.375\n",
       "x39            3.0541      0.375      8.136      0.000       2.318       3.790\n",
       "x40           -0.6161      0.380     -1.620      0.105      -1.361       0.129\n",
       "x41            9.3381      0.503     18.571      0.000       8.353      10.324\n",
       "x42           -0.1342      0.442     -0.304      0.761      -1.000       0.731\n",
       "x43           -0.3781      0.361     -1.047      0.295      -1.086       0.330\n",
       "x44           -0.2868      0.437     -0.657      0.511      -1.143       0.569\n",
       "x45           -0.5777      0.501     -1.153      0.249      -1.560       0.405\n",
       "x46            0.0794      0.352      0.226      0.822      -0.610       0.769\n",
       "x47           -0.6242      0.428     -1.458      0.145      -1.463       0.215\n",
       "x48            1.7625      0.473      3.724      0.000       0.835       2.690\n",
       "x49            1.6032      0.475      3.377      0.001       0.673       2.534\n",
       "x50           -0.6888      0.523     -1.318      0.187      -1.713       0.335\n",
       "x51           -1.5593      0.373     -4.180      0.000      -2.291      -0.828\n",
       "x52           -1.3940      0.357     -3.906      0.000      -2.094      -0.694\n",
       "x53            2.7611      0.436      6.328      0.000       1.906       3.616\n",
       "x54            5.7134      0.572      9.984      0.000       4.592       6.835\n",
       "x55            1.0591      0.379      2.797      0.005       0.317       1.801\n",
       "x56           -0.6089      0.471     -1.293      0.196      -1.532       0.314\n",
       "x57            0.0161      0.391      0.041      0.967      -0.749       0.782\n",
       "x58           -0.2279      0.384     -0.593      0.553      -0.981       0.526\n",
       "x59            1.8105      0.490      3.693      0.000       0.850       2.771\n",
       "x60           -3.8810      0.353    -11.005      0.000      -4.572      -3.190\n",
       "x61            2.1438      0.393      5.459      0.000       1.374       2.914\n",
       "x62           -4.7827      0.375    -12.743      0.000      -5.518      -4.047\n",
       "x63           -7.9012      0.445    -17.747      0.000      -8.774      -7.029\n",
       "x64            1.6443      0.561      2.933      0.003       0.546       2.743\n",
       "x65            1.0639      0.428      2.488      0.013       0.226       1.902\n",
       "x66           -1.5643      0.398     -3.929      0.000      -2.345      -0.784\n",
       "x67           -0.4831      0.342     -1.414      0.157      -1.153       0.186\n",
       "x68           -0.8788      0.405     -2.167      0.030      -1.673      -0.084\n",
       "x69           -2.0247      0.379     -5.345      0.000      -2.767      -1.282\n",
       "x70           -1.8683      0.359     -5.211      0.000      -2.571      -1.166\n",
       "x71           -0.5862      0.369     -1.589      0.112      -1.309       0.137\n",
       "x72           -0.0082      0.520     -0.016      0.987      -1.027       1.010\n",
       "x73            0.0284      0.395      0.072      0.943      -0.745       0.802\n",
       "x74           -2.7641      0.334     -8.268      0.000      -3.419      -2.109\n",
       "x75           -1.2452      0.363     -3.432      0.001      -1.956      -0.534\n",
       "x76            0.1721      0.383      0.450      0.653      -0.578       0.922\n",
       "x77            0.2530      0.365      0.694      0.488      -0.462       0.968\n",
       "x78            2.3712      0.403      5.889      0.000       1.582       3.160\n",
       "x79            0.0465      0.405      0.115      0.909      -0.748       0.841\n",
       "x80           -1.9348      0.316     -6.129      0.000      -2.554      -1.316\n",
       "x81           -1.4642      0.484     -3.028      0.002      -2.412      -0.516\n",
       "x82            1.1032      0.436      2.528      0.011       0.248       1.958\n",
       "x83            0.5998      0.406      1.477      0.140      -0.196       1.396\n",
       "x84            0.7346      0.382      1.923      0.054      -0.014       1.483\n",
       "x85            0.6221      0.390      1.595      0.111      -0.142       1.386\n",
       "x86           -0.8785      0.540     -1.628      0.103      -1.936       0.179\n",
       "x87           -2.6816      0.752     -3.564      0.000      -4.156      -1.207\n",
       "x88           -0.0840      0.407     -0.206      0.836      -0.881       0.713\n",
       "x89           -0.9477      0.393     -2.411      0.016      -1.718      -0.177\n",
       "x90           -1.1957      0.399     -2.996      0.003      -1.978      -0.413\n",
       "x91           -1.2974      0.440     -2.952      0.003      -2.159      -0.436\n",
       "x92           -2.8771      0.463     -6.217      0.000      -3.784      -1.970\n",
       "x93            0.3003      0.387      0.776      0.438      -0.459       1.059\n",
       "x94           -2.1412      0.680     -3.148      0.002      -3.474      -0.808\n",
       "x95            0.1729      0.377      0.458      0.647      -0.567       0.912\n",
       "x96            1.6550      0.403      4.109      0.000       0.866       2.444\n",
       "x97           -1.4514      0.384     -3.778      0.000      -2.204      -0.698\n",
       "x98           -0.4775      0.469     -1.018      0.308      -1.396       0.441\n",
       "x99            0.8007      0.410      1.955      0.051      -0.002       1.604\n",
       "x100           1.5401      0.371      4.149      0.000       0.813       2.268\n",
       "x101          -1.8043      0.558     -3.234      0.001      -2.898      -0.711\n",
       "x102           1.2876      0.602      2.140      0.032       0.108       2.467\n",
       "x103           0.9943      0.394      2.523      0.012       0.222       1.767\n",
       "x104          -1.3572      0.359     -3.776      0.000      -2.062      -0.653\n",
       "x105          -1.1242      0.467     -2.406      0.016      -2.040      -0.208\n",
       "x106          -1.4295      0.385     -3.712      0.000      -2.184      -0.675\n",
       "x107          -1.2631      0.403     -3.133      0.002      -2.053      -0.473\n",
       "x108          -0.2997      0.431     -0.696      0.486      -1.144       0.544\n",
       "x109           0.6491      0.378      1.717      0.086      -0.092       1.390\n",
       "x110           3.3332      0.507      6.572      0.000       2.339       4.327\n",
       "x111          -1.8873      0.407     -4.641      0.000      -2.684      -1.090\n",
       "x112           2.6487      0.528      5.012      0.000       1.613       3.684\n",
       "x113          -0.4267      0.383     -1.115      0.265      -1.176       0.323\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train statsmodels logit to view intercept\n",
    "import statsmodels.api as sm\n",
    "# f = feats_norm.A\n",
    "# logit = sm.Logit(data.is_positive.values, sm.add_constant(f))\n",
    "# logit = sm.Logit(data.is_positive.values, sm.add_constant(feats_norm))\n",
    "logit = sm.Logit(data.is_positive.values, sm.add_constant(feats_n))\n",
    "# logit = sm.Logit(data.is_positive.values, feats_n)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not</th>\n",
       "      <th>like</th>\n",
       "      <th>you</th>\n",
       "      <th>great</th>\n",
       "      <th>best</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not  like  you  great  best  is_positive\n",
       "0    1     0    0      0     0            0\n",
       "1    0     1    0      1     0            1\n",
       "2    0     1    1      1     0            1\n",
       "3    1     0    0      0     0            0\n",
       "4    1     0    0      1     1            1\n",
       "5    1     0    0      0     0            0\n",
       "6    1     1    0      0     0            0\n",
       "7    1     0    0      1     1            1\n",
       "8    0     0    0      1     0            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    ], columns=['not', 'like', 'you', 'great', 'best', 'is_positive'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PerfectSeparationError",
     "evalue": "Perfect separation detected, results not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPerfectSeparationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f8527bdd753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1967\u001b[0m                               \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                               \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                               **kwargs)\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m                              \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                              \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m  \u001b[0;31m# It is up to subclasses to wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m                                                        \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                                                        \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                                                        full_output=full_output)\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# NOTE: this is for fit_regularized and should be generalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    225\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                             hess=hessian)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         optim_settings = {'optimizer': method, 'start_params': start_params,\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit_newton\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0miterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mfval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is the negative likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36m_check_perfect_pred\u001b[0;34m(self, params, *args)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 np.allclose(fittedvalues - endog, 0)):\n\u001b[1;32m    210\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Perfect separation detected, results not available\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPerfectSeparationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPerfectSeparationError\u001b[0m: Perfect separation detected, results not available"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df.loc[:, ['not', 'like', 'you', 'great', 'best']]\n",
    "y = df.is_positive\n",
    "logit = sm.Logit(y, X)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Load, process Yelp review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c32fafa899e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreviews_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'yelp_academic_dataset_review.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 5.9G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-c32fafa899e7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreviews_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'yelp_academic_dataset_review.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 5.9G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "reviews_path = 'yelp_academic_dataset_review.json'\n",
    "with open(reviews_path) as f:  # 5.9G\n",
    "    reviews = [json.loads(next(f)) for x in range(int(1e7))]\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlines = []\n",
    "count = 1\n",
    "for review in reviews:\n",
    "    if review['stars'] >= 4:\n",
    "        rating = 'positive'\n",
    "    elif review['stars'] <= 2:\n",
    "        rating = 'negative'\n",
    "    else:\n",
    "        continue\n",
    "    outlines.append([review['text'], rating])\n",
    "    count += 1\n",
    "    if count > 10000:\n",
    "        break\n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out condensed data\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(outlines, columns=['review_text', 'rating'])\n",
    "outpath = 'review_sample.csv'\n",
    "data.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Sample Yelp review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Amazing food. Glorious bevs. What more could y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Wife and I have been going to Abuelos for year...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I had THE BEST VEGAN Gardein chicken plate wit...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Went there for the first time today and got ve...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>After my second time here I'm still leaving fu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text    rating\n",
       "0     As someone who has worked with many museums, I...  negative\n",
       "1     I am actually horrified this place is still in...  negative\n",
       "2     I love Deagan's. I do. I really do. The atmosp...  positive\n",
       "3     Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  negative\n",
       "4     Oh happy day, finally have a Canes near my cas...  positive\n",
       "...                                                 ...       ...\n",
       "9995  Amazing food. Glorious bevs. What more could y...  positive\n",
       "9996  Wife and I have been going to Abuelos for year...  negative\n",
       "9997  I had THE BEST VEGAN Gardein chicken plate wit...  positive\n",
       "9998  Went there for the first time today and got ve...  positive\n",
       "9999  After my second time here I'm still leaving fu...  positive\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load review data\n",
    "import pandas as pd\n",
    "path = 'review_sample10000.csv'\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    500\n",
       "positive    500\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced sampling between negative and positive ratings\n",
    "sample = pd.concat([data[data['rating']=='positive'].sample(500), data[data['rating']=='negative'].sample(500)])\n",
    "sample = sample.sample(frac=1) # shuffle\n",
    "sample['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out\n",
    "outpath = 'yelp_reviews_1000balanced.csv'\n",
    "sample.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Train sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 24634)\n",
      "(1000, 24634)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = int(0.1 * len(data))\n",
    "text_train, text_test, y_train, y_test = train_test_split(data['review_text'], data['rating'], test_size=test_size, random_state=7)\n",
    "corpus = data['review_text']\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "x_train = vectorizer.fit_transform(text_train) # corpus is a list of strings (documents)\n",
    "x_test = vectorizer.transform(text_test) # corpus is a list of strings (documents)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Try on AI experiences data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## From Yelp-trained logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Shiyan</th>\n",
       "      <th>Cansu</th>\n",
       "      <th>Jie</th>\n",
       "      <th>Madeline</th>\n",
       "      <th>Criteria</th>\n",
       "      <th>Other Notes</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siri knows the true meaning of Christmas, offe...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive as it's a good experience although th...</td>\n",
       "      <td>I thought it might be neutral, but then after ...</td>\n",
       "      <td>Started with a negative sacstic crique but lat...</td>\n",
       "      <td>Positive: Humor of experience, and knowing a l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weight towards what sentence?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the most common interactions I have wit...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral as it's a state of fact and it feels l...</td>\n",
       "      <td>I think the participant appreciates the opport...</td>\n",
       "      <td>The writer had a mixture of feelings toward AI...</td>\n",
       "      <td>Negative: Sense of \"too comfortable\" and too g...</td>\n",
       "      <td>If there is a transition from one side to the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I remember one day while I was in graduate sch...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The negative part comes from the writer's frie...</td>\n",
       "      <td>I think it is a funny story and in general, po...</td>\n",
       "      <td>Positive because AI technology seemed to be us...</td>\n",
       "      <td>Positive: The humor involved in pranks; AI as ...</td>\n",
       "      <td>AI technology itself, not the people using it</td>\n",
       "      <td>Humor as positive, involving minor misfortune;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last week, my family was talking about winter ...</td>\n",
       "      <td>Still debating</td>\n",
       "      <td>It tends to be negative as the writer did not ...</td>\n",
       "      <td>Positive; at first the attitude is negative bu...</td>\n",
       "      <td>Negative. Surprised, felt somewhat creepy, end...</td>\n",
       "      <td>Weird coincidence, so mildly negative; people ...</td>\n",
       "      <td>Would this person want to use AI or not? (Cansu)</td>\n",
       "      <td>Making inferences is a human thing; consistent...</td>\n",
       "      <td>No agreement on last quote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My Apple watch counts each hour in which I hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Would this person have this experience again? ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One of the most frustrating encounters with AI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Facebook tries to be helpful.  Whenever I am o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yesterday, I chatted with Emma, an agent that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I, like most people, use Google search several...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I love using navigation apps to get places. Es...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I love the youtube smart playlists.  At a cert...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Last month, I had a discussion with my friends...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My phone's AI has figured out that the first t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I do not remember the years that we have start...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text           Label  \\\n",
       "0   Siri knows the true meaning of Christmas, offe...        Positive   \n",
       "1   One of the most common interactions I have wit...        Positive   \n",
       "2   I remember one day while I was in graduate sch...        Positive   \n",
       "3   Last week, my family was talking about winter ...  Still debating   \n",
       "4   My Apple watch counts each hour in which I hav...             NaN   \n",
       "5   One of the most frustrating encounters with AI...             NaN   \n",
       "6   Facebook tries to be helpful.  Whenever I am o...             NaN   \n",
       "7   Yesterday, I chatted with Emma, an agent that ...             NaN   \n",
       "8   I, like most people, use Google search several...             NaN   \n",
       "9   I love using navigation apps to get places. Es...             NaN   \n",
       "10  I love the youtube smart playlists.  At a cert...             NaN   \n",
       "11  Last month, I had a discussion with my friends...             NaN   \n",
       "12  My phone's AI has figured out that the first t...             NaN   \n",
       "13  I do not remember the years that we have start...             NaN   \n",
       "\n",
       "                                               Shiyan  \\\n",
       "0   Positive as it's a good experience although th...   \n",
       "1   Neutral as it's a state of fact and it feels l...   \n",
       "2   The negative part comes from the writer's frie...   \n",
       "3   It tends to be negative as the writer did not ...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                                Cansu  \\\n",
       "0   I thought it might be neutral, but then after ...   \n",
       "1   I think the participant appreciates the opport...   \n",
       "2   I think it is a funny story and in general, po...   \n",
       "3   Positive; at first the attitude is negative bu...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                                  Jie  \\\n",
       "0   Started with a negative sacstic crique but lat...   \n",
       "1   The writer had a mixture of feelings toward AI...   \n",
       "2   Positive because AI technology seemed to be us...   \n",
       "3   Negative. Surprised, felt somewhat creepy, end...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                             Madeline  \\\n",
       "0   Positive: Humor of experience, and knowing a l...   \n",
       "1   Negative: Sense of \"too comfortable\" and too g...   \n",
       "2   Positive: The humor involved in pranks; AI as ...   \n",
       "3   Weird coincidence, so mildly negative; people ...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                             Criteria  \\\n",
       "0                                                 NaN   \n",
       "1   If there is a transition from one side to the ...   \n",
       "2       AI technology itself, not the people using it   \n",
       "3    Would this person want to use AI or not? (Cansu)   \n",
       "4   Would this person have this experience again? ...   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                                          Other Notes  \\\n",
       "0                       Weight towards what sentence?   \n",
       "1                                                 NaN   \n",
       "2   Humor as positive, involving minor misfortune;...   \n",
       "3   Making inferences is a human thing; consistent...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "\n",
       "                    Unnamed: 8  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3   No agreement on last quote  \n",
       "4                          NaN  \n",
       "5                          NaN  \n",
       "6                          NaN  \n",
       "7                          NaN  \n",
       "8                          NaN  \n",
       "9                          NaN  \n",
       "10                         NaN  \n",
       "11                         NaN  \n",
       "12                         NaN  \n",
       "13                         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '/home/mamille2/storyq/ai_experiences.csv'\n",
    "path = 'ai_experiences.csv'\n",
    "experiences = pd.read_csv(path)\n",
    "experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 24634)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = experiences['Text']\n",
    "bow = vectorizer.transform(corpus) # corpus is a list of strings (documents)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>yelp10k_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siri knows the true meaning of Christmas, offe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the most common interactions I have wit...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I remember one day while I was in graduate sch...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last week, my family was talking about winter ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My Apple watch counts each hour in which I hav...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One of the most frustrating encounters with AI...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Facebook tries to be helpful.  Whenever I am o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yesterday, I chatted with Emma, an agent that ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I, like most people, use Google search several...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I love using navigation apps to get places. Es...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I love the youtube smart playlists.  At a cert...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Last month, I had a discussion with my friends...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My phone's AI has figured out that the first t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I do not remember the years that we have start...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text yelp10k_classifier\n",
       "0   Siri knows the true meaning of Christmas, offe...           positive\n",
       "1   One of the most common interactions I have wit...           positive\n",
       "2   I remember one day while I was in graduate sch...           negative\n",
       "3   Last week, my family was talking about winter ...           positive\n",
       "4   My Apple watch counts each hour in which I hav...           negative\n",
       "5   One of the most frustrating encounters with AI...           positive\n",
       "6   Facebook tries to be helpful.  Whenever I am o...           positive\n",
       "7   Yesterday, I chatted with Emma, an agent that ...           negative\n",
       "8   I, like most people, use Google search several...           positive\n",
       "9   I love using navigation apps to get places. Es...           positive\n",
       "10  I love the youtube smart playlists.  At a cert...           positive\n",
       "11  Last month, I had a discussion with my friends...           positive\n",
       "12  My phone's AI has figured out that the first t...           positive\n",
       "13  I do not remember the years that we have start...           negative"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences['yelp10k_classifier'] = clf.predict(bow)\n",
    "experiences.loc[:, ['Text', 'yelp10k_classifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     positive\n",
       "1     positive\n",
       "2     negative\n",
       "3     positive\n",
       "4     negative\n",
       "5     positive\n",
       "6     positive\n",
       "7     negative\n",
       "8     positive\n",
       "9     positive\n",
       "10    positive\n",
       "11    positive\n",
       "12    positive\n",
       "13    negative\n",
       "Name: yelp10k_classifier, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiences['yelp10k_classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def print_top_features(vectorizer, clf, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    top_indices = np.argsort(clf.coef_[0])[-1*n:]\n",
    "    print(\"\\n\".join(reversed([feature_names[j] for j in top_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def print_bottom_features(vectorizer, clf, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    top_indices = np.argsort(clf.coef_[0])[:n]\n",
    "    print(\"\\n\".join(reversed([feature_names[j] for j in top_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n",
      "amazing\n",
      "delicious\n",
      "love\n",
      "best\n",
      "and\n",
      "awesome\n",
      "definitely\n",
      "friendly\n",
      "excellent\n",
      "always\n",
      "perfect\n",
      "good\n",
      "nice\n",
      "little\n",
      "loved\n",
      "fantastic\n",
      "very\n",
      "highly\n",
      "with\n"
     ]
    }
   ],
   "source": [
    "print_top_features(vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow\n",
      "then\n",
      "won\n",
      "left\n",
      "poor\n",
      "nothing\n",
      "money\n",
      "bad\n",
      "over\n",
      "asked\n",
      "told\n",
      "ok\n",
      "bland\n",
      "horrible\n",
      "never\n",
      "terrible\n",
      "rude\n",
      "worst\n",
      "no\n",
      "not\n"
     ]
    }
   ],
   "source": [
    "print_bottom_features(vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_informative_features(features_vectorizer, model, model_name, data_dirpath, n=10000):\n",
    "    feats_index2name = {v: k for k, v in features_vectorizer.vocabulary_.items()}\n",
    "    feature_weights = model.coef_[0]\n",
    "    \n",
    "    top_indices = np.argsort(feature_weights)[-1*n:]\n",
    "    top_weights = np.sort(feature_weights)[-1*n:]\n",
    "    bottom_indices = np.argsort(feature_weights)[:n]\n",
    "    bottom_weights = np.sort(feature_weights)[:n]\n",
    "\n",
    "    nontag_lines = [] # to sort and print\n",
    "    lines = [] # to sort and print\n",
    "    \n",
    "    for i, (j, w) in enumerate(zip(reversed(top_indices), reversed(top_weights))):\n",
    "        feature_name = feats_index2name[j]\n",
    "        if not feature_name.startswith('tag'):\n",
    "            nontag_lines.append([i, feature_name, w, abs(w)])\n",
    "#             print(f\"{i}\\t{feature_name}\\t{w: .3f}\")\n",
    "        lines.append([i, feature_name, w, abs(w)])\n",
    "    \n",
    "    for i, (j, w) in enumerate(zip(bottom_indices, bottom_weights)):\n",
    "        feature_name = feats_index2name[j]\n",
    "        if not feature_name.startswith('tag'):\n",
    "            nontag_lines.append([i, feature_name, w, abs(w)])\n",
    "        lines.append([i, feature_name, w, abs(w)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## From NLTK SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy' has no attribute '_lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8838b6bcfd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/nltk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Import top-level functionality into top-level namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollocations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatstruct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# these two unused imports are referenced in collocations.doctest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m from nltk.metrics import (\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mContingencyMeasures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mBigramAssocMeasures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/nltk/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from nltk.metrics.scores import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/nltk/metrics/scores.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbetai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbetai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \"\"\"\n\u001b[0;32m--> 388\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                     rv_frozen)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# for root finding for continuous distribution ppf, and max likelihood estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/optimize/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    385\u001b[0m \"\"\"\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_minimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                          \u001b[0mline_search_wolfe2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mline_search\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                          LineSearchWarning)\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_numdiff\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapprox_derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetfullargspec_no_self\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMapWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsc_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_group_columns\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgroup_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/sparse/linalg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \"\"\"\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0misolve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdsolve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/sparse/linalg/isolve/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#from info import __doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0miterative\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mminres\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlgmres\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlgmres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/sparse/linalg/isolve/iterative.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m                )\n\u001b[1;32m    149\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mnon_reentrant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mbicg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpostprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/_lib/_threadsafety.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s is not re-entrant\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReentrancyLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/scipy/_lib/_threadsafety.py\u001b[0m in \u001b[0;36mdecorate\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy' has no attribute '_lib'"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
